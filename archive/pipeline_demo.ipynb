{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Build Vault Pipeline Demo\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook processes a real podcast episode through the complete pipeline:\n",
    "- Downloads actual audio from YouTube\n",
    "- Transcribes using AssemblyAI\n",
    "- Extracts insights with GPT-4\n",
    "- Generates real embeddings\n",
    "- Stores in Supabase database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Checking and installing required packages...\n",
      "üêç Python: /Users/cam/GITHUB/build-vault-embeddings-demo/myenv/bin/python\n",
      "üì¶ Virtual environment: Yes\n",
      "‚úÖ supabase is already installed\n",
      "‚úÖ python-dotenv is already installed\n",
      "‚úÖ langchain-openai is already installed\n",
      "‚úÖ assemblyai is already installed\n",
      "‚úÖ youtube-dl is already installed\n",
      "‚úÖ pandas is already installed\n",
      "‚úÖ matplotlib is already installed\n",
      "‚úÖ seaborn is already installed\n",
      "‚úÖ requests is already installed\n",
      "‚úÖ beautifulsoup4 is already installed\n",
      "‚úÖ jupyter is already installed\n",
      "‚úÖ ipykernel is already installed\n",
      "\n",
      " All required packages are already installed!\n",
      "\n",
      "üí° Make sure you're using the correct Jupyter kernel:\n",
      "   Kernel ‚Üí Change kernel ‚Üí Build Vault (myenv)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üì¶ Checking and installing required packages...\")\n",
    "\n",
    "# Define packages to install\n",
    "packages = [\n",
    "    \"supabase\",\n",
    "    \"python-dotenv\",\n",
    "    \"langchain-openai\",\n",
    "    \"assemblyai\",\n",
    "    \"youtube-dl\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\", \n",
    "    \"seaborn\",\n",
    "    \"requests\",\n",
    "    \"beautifulsoup4\",\n",
    "    \"jupyter\",\n",
    "    \"ipykernel\"\n",
    "]\n",
    "\n",
    "# Check if we're in a virtual environment\n",
    "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "print(f\"üêç Python: {sys.executable}\")\n",
    "print(f\"üì¶ Virtual environment: {'Yes' if in_venv else 'No'}\")\n",
    "\n",
    "# Install packages using pip\n",
    "missing_packages = []\n",
    "for package in packages:\n",
    "    try:\n",
    "        # Try to import the package\n",
    "        if package == \"beautifulsoup4\":\n",
    "            __import__(\"bs4\")\n",
    "        elif package == \"python-dotenv\":\n",
    "            __import__(\"dotenv\")\n",
    "        elif package == \"langchain-openai\":\n",
    "            __import__(\"langchain_openai\")\n",
    "        elif package == \"youtube-dl\":\n",
    "            __import__(\"youtube_dl\")\n",
    "        else:\n",
    "            __import__(package)\n",
    "        print(f\"‚úÖ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        missing_packages.append(package)\n",
    "        print(f\"‚ùå {package} is not installed\")\n",
    "\n",
    "# Install missing packages\n",
    "if missing_packages:\n",
    "    print(f\"\\nüì¶ Installing {len(missing_packages)} missing packages...\")\n",
    "    for package in missing_packages:\n",
    "        try:\n",
    "            print(f\"Installing {package}...\")\n",
    "            result = subprocess.run(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                capture_output=True, \n",
    "                text=True,\n",
    "                timeout=60\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                print(f\" {package} installed successfully\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed to install {package}: {result.stderr}\")\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"‚è∞ {package} installation timed out\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error installing {package}: {e}\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è If packages were just installed, you may need to restart the kernel:\")\n",
    "    print(\"   Kernel ‚Üí Restart Kernel\")\n",
    "else:\n",
    "    print(\"\\n All required packages are already installed!\")\n",
    "\n",
    "print(\"\\nüí° Make sure you're using the correct Jupyter kernel:\")\n",
    "print(\"   Kernel ‚Üí Change kernel ‚Üí Build Vault (myenv)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/cam/GITHUB/build-vault-embeddings-demo\n",
      "Parent directory added to path: /Users/cam/GITHUB\n",
      "Python path: ['/Users/cam/GITHUB', '/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python313.zip']\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Markdown, clear_output\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('demo'):\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "else:\n",
    "    # If running from parent directory\n",
    "    parent_dir = current_dir\n",
    "\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "print(f\"Parent directory added to path: {parent_dir}\")\n",
    "print(f\"Python path: {sys.path[:2]}\")\n",
    "\n",
    "# Configure visualization\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded environment variables from /Users/cam/GITHUB/build-vault-embeddings-demo/.env\n",
      "\n",
      "üîç Checking environment variables:\n",
      " YOUTUBE_API_KEY: AIzaSyAv5Jq5CIgC479_...\n",
      " ASSEMBLYAI_API_KEY: 9081a5edb220442f83c5...\n",
      " OPENAI_API_KEY: sk-proj-3Ve3BKuSOh8o...\n",
      " SUPABASE_URL: https://hyvhvbgcwfnq...\n",
      " SUPABASE_ANON_KEY: eyJhbGciOiJIUzI1NiIs...\n",
      "\n",
      "üéâ All required environment variables are loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file from current directory\n",
    "env_path = os.path.join(os.getcwd(), '.env')\n",
    "if os.path.exists(env_path):\n",
    "    load_dotenv(env_path, override=True)\n",
    "    print(f\"‚úÖ Loaded environment variables from {env_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå No .env file found at {env_path}\")\n",
    "\n",
    "# Verify environment variables are loaded\n",
    "print(\"\\nüîç Checking environment variables:\")\n",
    "required_vars = [\n",
    "    'YOUTUBE_API_KEY',\n",
    "    'ASSEMBLYAI_API_KEY', \n",
    "    'OPENAI_API_KEY',\n",
    "    'SUPABASE_URL',\n",
    "    'SUPABASE_ANON_KEY'\n",
    "]\n",
    "\n",
    "all_set = True\n",
    "for var in required_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        # Show only first few characters for security\n",
    "        print(f\" {var}: {value[:20]}...\" if len(value) > 20 else f\" {var}: Set\")\n",
    "    else:\n",
    "        print(f\"‚ùå {var}: Not set\")\n",
    "        all_set = False\n",
    "\n",
    "if all_set:\n",
    "    print(\"\\nüéâ All required environment variables are loaded!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some environment variables are missing. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No .env file found at /Users/cam/GITHUB/.env\n",
      "Make sure to set environment variables manually or create a .env file\n",
      " SUPABASE_URL: https://hyvhvbgcwfnq...\n",
      " SUPABASE_ANON_KEY: eyJhbGciOiJIUzI1NiIs...\n",
      " OPENAI_API_KEY: sk-proj-3Ve3BKuSOh8o...\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Try to load .env from parent directory\n",
    "env_path = os.path.join(parent_dir, '.env')\n",
    "if os.path.exists(env_path):\n",
    "    load_dotenv(env_path)\n",
    "    print(f\" Loaded environment variables from {env_path}\")\n",
    "else:\n",
    "    print(f\" No .env file found at {env_path}\")\n",
    "    print(\"Make sure to set environment variables manually or create a .env file\")\n",
    "\n",
    "# Verify key variables are loaded (show only first few characters for security)\n",
    "import os\n",
    "for var in ['SUPABASE_URL', 'SUPABASE_ANON_KEY', 'OPENAI_API_KEY']:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        print(f\" {var}: {value[:20]}...\")\n",
    "    else:\n",
    "        print(f\"‚ùå {var}: Not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Importing pipeline modules...\n",
      " Configuration loaded\n",
      " Supabase client imported\n",
      " AudioDownloader imported\n",
      " TranscriptionService imported\n",
      " SegmentProcessor imported\n",
      "‚úÖ EpisodeSummaryGenerator imported\n",
      " InsightExtractor imported\n",
      " ProductExtractor imported\n",
      " LinkExtractor imported\n",
      " LinkEnricher imported\n",
      "\n",
      "üéâ Successfully imported all pipeline modules!\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline modules\n",
    "print(\"üîÑ Importing pipeline modules...\")\n",
    "\n",
    "try:\n",
    "    # Import configuration first\n",
    "    from shared.config import (\n",
    "        YOUTUBE_API_KEY, ASSEMBLYAI_API_KEY, OPENAI_API_KEY,\n",
    "        SUPABASE_URL, SUPABASE_ANON_KEY\n",
    "    )\n",
    "    print(\" Configuration loaded\")\n",
    "    \n",
    "    # Import Supabase client\n",
    "    from shared.supabase_client import get_supabase_client\n",
    "    print(\" Supabase client imported\")\n",
    "    \n",
    "    # Import pipeline modules\n",
    "    from pipeline.audio_downloader import AudioDownloader\n",
    "    print(\" AudioDownloader imported\")\n",
    "    \n",
    "    from pipeline.transcription_service import TranscriptionService\n",
    "    print(\" TranscriptionService imported\")\n",
    "    \n",
    "    from pipeline.segment_processor import SegmentProcessor\n",
    "    print(\" SegmentProcessor imported\")\n",
    "    \n",
    "    from pipeline.episode_summary_generator import EpisodeSummaryGenerator\n",
    "    print(\"‚úÖ EpisodeSummaryGenerator imported\")\n",
    "    \n",
    "    from pipeline.insight_extractor import InsightExtractor\n",
    "    print(\" InsightExtractor imported\")\n",
    "    \n",
    "    from pipeline.product_extractor import ProductExtractor\n",
    "    print(\" ProductExtractor imported\")\n",
    "    \n",
    "    from pipeline.link_extractor import LinkExtractor\n",
    "    print(\" LinkExtractor imported\")\n",
    "    \n",
    "    from pipeline.link_enricher import LinkEnricher\n",
    "    print(\" LinkEnricher imported\")\n",
    "    \n",
    "    print(\"\\nüéâ Successfully imported all pipeline modules!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"\\nDebugging information:\")\n",
    "    print(f\"- Current directory: {os.getcwd()}\")\n",
    "    print(f\"- Python path: {sys.path[0]}\")\n",
    "    \n",
    "    # Check if specific modules exist\n",
    "    import glob\n",
    "    pipeline_files = glob.glob('../pipeline/*.py')\n",
    "    shared_files = glob.glob('../shared/*.py')\n",
    "    \n",
    "    print(f\"- Pipeline files found: {len(pipeline_files)}\")\n",
    "    print(f\"- Shared files found: {len(shared_files)}\")\n",
    "    \n",
    "    print(\"\\nTry installing missing dependencies:\")\n",
    "    print(\"  uv pip install supabase python-dotenv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\")\n",
    "    print(\"Make sure all dependencies are installed and environment variables are set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Checking and installing dependencies...\n",
      "‚úÖ supabase already installed\n",
      "üì¶ Installing python-dotenv...\n",
      "Requirement already satisfied: python-dotenv in ./myenv/lib/python3.13/site-packages (1.1.1)\n",
      "‚úÖ python-dotenv installed successfully\n",
      "‚úÖ langchain-openai already installed\n",
      "‚úÖ assemblyai already installed\n",
      "‚úÖ youtube-dl already installed\n",
      "üîÑ Restarting kernel may be required for new installations...\n"
     ]
    }
   ],
   "source": [
    "# Install missing dependencies if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        return True\n",
    "    except subprocess.CalledProcessError:\n",
    "        return False\n",
    "\n",
    "# Check and install required packages\n",
    "required_packages = [\n",
    "    \"supabase\",\n",
    "    \"python-dotenv\",\n",
    "    \"langchain-openai\",\n",
    "    \"assemblyai\",\n",
    "    \"youtube-dl\"\n",
    "]\n",
    "\n",
    "print(\"üîß Checking and installing dependencies...\")\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úÖ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {package}...\")\n",
    "        if install_package(package):\n",
    "            print(f\"‚úÖ {package} installed successfully\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to install {package}\")\n",
    "\n",
    "print(\"üîÑ Restarting kernel may be required for new installations...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration options\n",
    "DEMO_MODE = True  # Set to False to process a full episode\n",
    "YOUTUBE_URL = \"https://www.youtube.com/watch?v=au5tYEwRiG8\"  # Your specified video\n",
    "EXISTING_EPISODE_ID = None  # Or provide an existing episode UUID\n",
    "\n",
    "# Processing options\n",
    "SKIP_EXISTING = True  # Skip stages that have already been completed\n",
    "MAX_INSIGHTS = 10  # Limit insights for demo (None for no limit)\n",
    "MAX_SEGMENTS = 5  # Limit segments for demo (None for no limit)\n",
    "\n",
    "if DEMO_MODE:\n",
    "    display(HTML(\"\"\"\n",
    "    <div style='background: #fff3cd; border: 1px solid #ffeaa7; padding: 15px; border-radius: 5px;'>\n",
    "        <strong>üéØ Demo Mode Active</strong><br>\n",
    "        Processing will be limited to save API costs:\n",
    "        <ul style='margin: 5px 0;'>\n",
    "            <li>Max {MAX_INSIGHTS} insights</li>\n",
    "            <li>Max {MAX_SEGMENTS} segments</li>\n",
    "            <li>Using smaller models where possible</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\".format(MAX_INSIGHTS=MAX_INSIGHTS, MAX_SEGMENTS=MAX_SEGMENTS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background: #fff3cd; border: 1px solid #ffeaa7; padding: 15px; border-radius: 5px;'>\n",
       "        <strong>üéØ Demo Mode Active</strong><br>\n",
       "        Processing will be limited to save API costs:\n",
       "        <ul style='margin: 5px 0;'>\n",
       "            <li>Max 10 insights</li>\n",
       "            <li>Max 5 segments</li>\n",
       "            <li>Using smaller models where possible</li>\n",
       "        </ul>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration options\n",
    "DEMO_MODE = True  # Set to False to process a full episode\n",
    "YOUTUBE_URL = \"https://www.youtube.com/watch?v=au5tYEwRiG8\"  # Your specified video\n",
    "EXISTING_EPISODE_ID = None  # Or provide an existing episode UUID\n",
    "\n",
    "# Processing options\n",
    "SKIP_EXISTING = True  # Skip stages that have already been completed\n",
    "MAX_INSIGHTS = 10  # Limit insights for demo (None for no limit)\n",
    "MAX_SEGMENTS = 5  # Limit segments for demo (None for no limit)\n",
    "\n",
    "if DEMO_MODE:\n",
    "    display(HTML(\"\"\"\n",
    "    <div style='background: #fff3cd; border: 1px solid #ffeaa7; padding: 15px; border-radius: 5px;'>\n",
    "        <strong>üéØ Demo Mode Active</strong><br>\n",
    "        Processing will be limited to save API costs:\n",
    "        <ul style='margin: 5px 0;'>\n",
    "            <li>Max {MAX_INSIGHTS} insights</li>\n",
    "            <li>Max {MAX_SEGMENTS} segments</li>\n",
    "            <li>Using smaller models where possible</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\".format(MAX_INSIGHTS=MAX_INSIGHTS, MAX_SEGMENTS=MAX_SEGMENTS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Database Connection\n",
    "\n",
    "Connect to Supabase to store and retrieve pipeline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to Supabase!\n",
      "üìä Database contains 13 episodes\n",
      "Database tables:\n",
      "   üìã transcriptions: 13 records\n",
      "   üìã segments: 1825 records\n",
      "   üìã insights: 1631 records\n",
      "   üìã products: 502 records\n",
      "   üìã speakers: 2 records\n"
     ]
    }
   ],
   "source": [
    "# Initialize Supabase client\n",
    "try:\n",
    "    supabase = get_supabase_client()\n",
    "    \n",
    "    # Test connection using correct table name from your schema\n",
    "    result = supabase.table('podcast_episodes').select('id').limit(1).execute()\n",
    "    print(\"‚úÖ Successfully connected to Supabase!\")\n",
    "    \n",
    "    # Show episode count\n",
    "    count_result = supabase.table('podcast_episodes').select('id', count='exact').execute()\n",
    "    print(f\"üìä Database contains {count_result.count} episodes\")\n",
    "    \n",
    "    # Show other available tables\n",
    "    tables_info = []\n",
    "    table_names = ['transcriptions', 'segments', 'insights', 'products', 'speakers']\n",
    "    \n",
    "    for table_name in table_names:\n",
    "        try:\n",
    "            count_result = supabase.table(table_name).select('id', count='exact').execute()\n",
    "            tables_info.append(f\"   üìã {table_name}: {count_result.count} records\")\n",
    "        except:\n",
    "            tables_info.append(f\"   ‚ö†Ô∏è {table_name}: table not accessible\")\n",
    "    \n",
    "    print(\"Database tables:\")\n",
    "    print(\"\\n\".join(tables_info))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database connection error: {e}\")\n",
    "    print(\"Make sure your Supabase credentials are correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Audio Download\n",
    "\n",
    "Download audio from YouTube or use existing episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ Downloading audio from: https://www.youtube.com/watch?v=au5tYEwRiG8\n",
      "‚úÖ Episode already exists: The Build - ChatGPT Connectors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 10px 0;'>\n",
       "        <h4 style='margin: 0 0 10px 0;'>üì∫ Episode Information</h4>\n",
       "        <p><strong>Title:</strong> The Build - ChatGPT Connectors</p>\n",
       "        <p><strong>YouTube ID:</strong> au5tYEwRiG8</p>\n",
       "        <p><strong>Duration:</strong> 0 seconds</p>\n",
       "        <p><strong>Published:</strong> Unknown</p>\n",
       "        <p><strong>Status:</strong> extracted</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize audio downloader\n",
    "downloader = AudioDownloader()\n",
    "episode_id = None\n",
    "episode_data = None\n",
    "\n",
    "if EXISTING_EPISODE_ID:\n",
    "    # Use existing episode\n",
    "    result = supabase.table('podcast_episodes').select('*').eq('id', EXISTING_EPISODE_ID).single().execute()\n",
    "    if result.data:\n",
    "        episode_data = result.data\n",
    "        episode_id = episode_data['id']\n",
    "        print(f\"‚úÖ Using existing episode: {episode_data['title']}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Episode {EXISTING_EPISODE_ID} not found!\")\n",
    "else:\n",
    "    # Download new episode\n",
    "    print(f\"üéµ Downloading audio from: {YOUTUBE_URL}\")\n",
    "    \n",
    "    try:\n",
    "        # Check if already exists using correct table name\n",
    "        video_id = YOUTUBE_URL.split('v=')[-1].split('&')[0]\n",
    "        existing = supabase.table('podcast_episodes').select('*').eq('youtube_video_id', video_id).execute()\n",
    "        \n",
    "        if existing.data and SKIP_EXISTING:\n",
    "            episode_data = existing.data[0]\n",
    "            episode_id = episode_data['id']\n",
    "            print(f\"‚úÖ Episode already exists: {episode_data['title']}\")\n",
    "        else:\n",
    "            # Download new\n",
    "            result = downloader.download_audio(YOUTUBE_URL)\n",
    "            if result:\n",
    "                episode_id = result['episode_id']\n",
    "                episode_data = supabase.table('podcast_episodes').select('*').eq('id', episode_id).single().execute().data\n",
    "                print(f\"‚úÖ Downloaded: {episode_data['title']}\")\n",
    "            else:\n",
    "                print(\"‚ùå Failed to download audio\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Download error: {e}\")\n",
    "\n",
    "# Display episode info\n",
    "if episode_data:\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style='background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 10px 0;'>\n",
    "        <h4 style='margin: 0 0 10px 0;'>üì∫ Episode Information</h4>\n",
    "        <p><strong>Title:</strong> {episode_data['title']}</p>\n",
    "        <p><strong>YouTube ID:</strong> {episode_data.get('youtube_video_id', 'N/A')}</p>\n",
    "        <p><strong>Duration:</strong> {episode_data.get('duration', 0)} seconds</p>\n",
    "        <p><strong>Published:</strong> {episode_data.get('published_at', 'Unknown')}</p>\n",
    "        <p><strong>Status:</strong> {episode_data.get('status', 'Unknown')}</p>\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found existing transcription with 1 segments\n",
      "\n",
      "üìä Available columns: ['id', 'episode_id', 'transcription_id', 'speaker_id', 'start_time', 'end_time', 'raw_text', 'display_text', 'title', 'created_at', 'segment_order', 'duration', 'speaker', 'topic', 'segment_type', 'ai_enhanced', 'confidence', 'word_count', 'updated_at', 'key_phrases', 'embedding_model', 'embedding_generated', 'embedding', 'category_hint', 'technical_tools', 'speaker_label', 'search_vector']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üìù Transcript Sample"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Using text column: display_text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>display_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0s</td>\n",
       "      <td>Cameron Rohn</td>\n",
       "      <td>OpenAI has recently introduced connectors that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_time       speaker                                       display_text\n",
       "0      80.0s  Cameron Rohn  OpenAI has recently introduced connectors that..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìú Full Transcript"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='margin: 10px 0; padding: 10px; background: #f5f5f5; border-left: 3px solid #2196F3;'>\n",
       "                <strong>Cameron Rohn</strong> <span style='color: #666; font-size: 12px;'>(80.0s)</span><br>\n",
       "                OpenAI has recently introduced connectors that are currently read-only. These connectors enable users to perform advanced search and in-depth research tasks, but do not yet support write operations. Each connector offers unique configuration options tailored to specific use cases.\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üé§ Speaker Statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cameron Rohn: 47010.0 seconds (783.5 minutes)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if transcription exists\n",
    "segments = []\n",
    "if episode_id:\n",
    "    existing_segments = supabase.table('segments').select('*').eq('episode_id', episode_id).order('start_time').execute()\n",
    "    \n",
    "    if existing_segments.data and SKIP_EXISTING:\n",
    "        segments = existing_segments.data\n",
    "        print(f\"‚úÖ Found existing transcription with {len(segments)} segments\")\n",
    "    else:\n",
    "        # Transcribe audio\n",
    "        print(\"üéôÔ∏è Starting transcription with AssemblyAI...\")\n",
    "        transcriber = TranscriptionService()\n",
    "        \n",
    "        try:\n",
    "            # Get audio file path from episode data\n",
    "            video_id = episode_data.get('youtube_video_id', '')\n",
    "            audio_path = os.path.join(os.path.dirname(__file__), '..', 'audio_storage', f'{video_id}.mp3')\n",
    "            \n",
    "            # Check if file exists\n",
    "            if not os.path.exists(audio_path):\n",
    "                # Try alternative path\n",
    "                audio_path = os.path.join(os.getcwd(), 'audio_storage', f'{video_id}.mp3')\n",
    "            \n",
    "            if os.path.exists(audio_path):\n",
    "                print(f\"üìÅ Audio file found: {audio_path}\")\n",
    "                \n",
    "                # Start transcription\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Show progress\n",
    "                print(\"‚è≥ Transcribing audio (this may take a few minutes)...\")\n",
    "                \n",
    "                # Actually transcribe\n",
    "                segments = transcriber.transcribe_audio(audio_path, episode_id)\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                if segments:\n",
    "                    print(f\"\\n‚úÖ Transcription complete! {len(segments)} segments in {elapsed:.1f}s\")\n",
    "                else:\n",
    "                    print(f\"\\n‚ö†Ô∏è No segments returned from transcription\")\n",
    "                    # Try to fetch from database in case they were saved\n",
    "                    segments = supabase.table('segments').select('*').eq('episode_id', episode_id).order('start_time').execute().data\n",
    "            else:\n",
    "                print(f\"‚ùå Audio file not found: {audio_path}\")\n",
    "                print(f\"Current directory: {os.getcwd()}\")\n",
    "                print(f\"Looking for video ID: {video_id}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Transcription error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Display segment samples\n",
    "if segments:\n",
    "    # Apply demo limit\n",
    "    display_segments = segments[:MAX_SEGMENTS] if DEMO_MODE and MAX_SEGMENTS else segments\n",
    "    \n",
    "    if len(display_segments) < len(segments):\n",
    "        print(f\"üìå Demo mode: Showing first {MAX_SEGMENTS} of {len(segments)} segments\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_segments = pd.DataFrame(display_segments)\n",
    "    \n",
    "    # Check what columns we have\n",
    "    print(f\"\\nüìä Available columns: {list(df_segments.columns)}\")\n",
    "    \n",
    "    # Calculate duration if needed\n",
    "    if 'duration' not in df_segments.columns and 'start_time' in df_segments.columns and 'end_time' in df_segments.columns:\n",
    "        df_segments['duration'] = df_segments['end_time'] - df_segments['start_time']\n",
    "    \n",
    "    # Show sample - use the correct column names\n",
    "    display(Markdown(\"### üìù Transcript Sample\"))\n",
    "    \n",
    "    # Determine which text column to use\n",
    "    text_col = None\n",
    "    if 'display_text' in df_segments.columns:\n",
    "        text_col = 'display_text'\n",
    "    elif 'raw_text' in df_segments.columns:\n",
    "        text_col = 'raw_text'\n",
    "    elif 'text' in df_segments.columns:\n",
    "        text_col = 'text'\n",
    "    \n",
    "    if text_col:\n",
    "        print(f\"üìù Using text column: {text_col}\")\n",
    "    \n",
    "    # Show relevant columns\n",
    "    columns_to_show = []\n",
    "    if 'start_time' in df_segments.columns:\n",
    "        columns_to_show.append('start_time')\n",
    "    if 'speaker' in df_segments.columns:\n",
    "        columns_to_show.append('speaker')\n",
    "    if text_col:\n",
    "        columns_to_show.append(text_col)\n",
    "    \n",
    "    if columns_to_show:\n",
    "        # Format start_time for readability\n",
    "        df_display = df_segments[columns_to_show].copy()\n",
    "        if 'start_time' in df_display.columns:\n",
    "            df_display['start_time'] = df_display['start_time'].apply(lambda x: f\"{x:.1f}s\")\n",
    "        \n",
    "        display(df_display.head())\n",
    "        \n",
    "        # Show full transcript in a nice format\n",
    "        display(Markdown(\"### üìú Full Transcript\"))\n",
    "        for idx, row in df_segments.iterrows():\n",
    "            if idx >= 5:  # Limit display\n",
    "                display(Markdown(f\"*... and {len(df_segments) - 5} more segments*\"))\n",
    "                break\n",
    "            \n",
    "            speaker = row.get('speaker', 'Unknown')\n",
    "            text = row.get(text_col, '')\n",
    "            start = row.get('start_time', 0)\n",
    "            \n",
    "            display(HTML(f\"\"\"\n",
    "            <div style='margin: 10px 0; padding: 10px; background: #f5f5f5; border-left: 3px solid #2196F3;'>\n",
    "                <strong>{speaker}</strong> <span style='color: #666; font-size: 12px;'>({start:.1f}s)</span><br>\n",
    "                {text}\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No text columns found. Available columns:\", list(df_segments.columns))\n",
    "        display(df_segments.head())\n",
    "    \n",
    "    # Speaker distribution\n",
    "    if 'speaker' in df_segments.columns and 'duration' in df_segments.columns:\n",
    "        speaker_stats = df_segments.groupby('speaker')['duration'].sum()\n",
    "        \n",
    "        if not speaker_stats.empty:\n",
    "            display(Markdown(\"### üé§ Speaker Statistics\"))\n",
    "            for speaker, duration in speaker_stats.items():\n",
    "                print(f\"  {speaker}: {duration:.1f} seconds ({duration/60:.1f} minutes)\")\n",
    "            \n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.pie(speaker_stats.values, labels=speaker_stats.index, autopct='%1.1f%%')\n",
    "            plt.title('Speaker Time Distribution')\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No segments found. The transcription may have failed or the episode might not have been transcribed yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if transcription exists\n",
    "segments = []\n",
    "if episode_id:\n",
    "    existing_segments = supabase.table('segments').select('*').eq('episode_id', episode_id).order('start_time').execute()\n",
    "    \n",
    "    if existing_segments.data and SKIP_EXISTING:\n",
    "        segments = existing_segments.data\n",
    "        print(f\"‚úÖ Found existing transcription with {len(segments)} segments\")\n",
    "    else:\n",
    "        # Transcribe audio\n",
    "        print(\"üéôÔ∏è Starting transcription with AssemblyAI...\")\n",
    "        transcriber = TranscriptionService()\n",
    "        \n",
    "        try:\n",
    "            # Get audio file path from episode data\n",
    "            video_id = episode_data.get('youtube_video_id', '')\n",
    "            audio_path = os.path.join(os.path.dirname(__file__), 'audio_storage', f'{video_id}.mp3')\n",
    "            \n",
    "            if os.path.exists(audio_path):\n",
    "                # Start transcription\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Show progress\n",
    "                with transcriber.transcribe_with_progress(audio_path, episode_id) as progress:\n",
    "                    for update in progress:\n",
    "                        clear_output(wait=True)\n",
    "                        display(HTML(f\"\"\"\n",
    "                        <div style='background: #e3f2fd; padding: 15px; border-radius: 5px;'>\n",
    "                            <strong>üéôÔ∏è Transcription Progress</strong><br>\n",
    "                            Status: {update.get('status', 'Processing...')}<br>\n",
    "                            {update.get('message', '')}\n",
    "                        </div>\n",
    "                        \"\"\"))\n",
    "                        time.sleep(1)\n",
    "                \n",
    "                # Actually transcribe\n",
    "                segments = transcriber.transcribe_audio(audio_path, episode_id)\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"\\n‚úÖ Transcription complete! {len(segments)} segments in {elapsed:.1f}s\")\n",
    "            else:\n",
    "                print(f\"‚ùå Audio file not found: {audio_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Transcription error: {e}\")\n",
    "\n",
    "# Display segment samples\n",
    "if segments:\n",
    "    # Apply demo limit\n",
    "    if DEMO_MODE and MAX_SEGMENTS:\n",
    "        segments = segments[:MAX_SEGMENTS]\n",
    "        print(f\"üìå Demo mode: Showing first {MAX_SEGMENTS} segments\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_segments = pd.DataFrame(segments)\n",
    "    \n",
    "    # Check what columns we have\n",
    "    print(f\"Available columns: {list(df_segments.columns)}\")\n",
    "    \n",
    "    # Calculate duration if needed\n",
    "    if 'duration' not in df_segments.columns and 'start_time' in df_segments.columns and 'end_time' in df_segments.columns:\n",
    "        df_segments['duration'] = df_segments['end_time'] - df_segments['start_time']\n",
    "    \n",
    "    # Show sample - use the correct column names\n",
    "    display(Markdown(\"### üìù Transcript Sample\"))\n",
    "    \n",
    "    # Determine which text column to use\n",
    "    text_col = None\n",
    "    if 'display_text' in df_segments.columns:\n",
    "        text_col = 'display_text'\n",
    "    elif 'raw_text' in df_segments.columns:\n",
    "        text_col = 'raw_text'\n",
    "    elif 'text' in df_segments.columns:\n",
    "        text_col = 'text'\n",
    "    \n",
    "    # Show relevant columns\n",
    "    columns_to_show = []\n",
    "    if 'start_time' in df_segments.columns:\n",
    "        columns_to_show.append('start_time')\n",
    "    if 'end_time' in df_segments.columns:\n",
    "        columns_to_show.append('end_time')\n",
    "    if 'speaker' in df_segments.columns:\n",
    "        columns_to_show.append('speaker')\n",
    "    if text_col:\n",
    "        columns_to_show.append(text_col)\n",
    "    \n",
    "    if columns_to_show:\n",
    "        display(df_segments[columns_to_show].head())\n",
    "    else:\n",
    "        display(df_segments.head())\n",
    "    \n",
    "    # Speaker distribution\n",
    "    if 'speaker' in df_segments.columns and 'duration' in df_segments.columns:\n",
    "        speaker_stats = df_segments.groupby('speaker')['duration'].sum()\n",
    "        \n",
    "        if not speaker_stats.empty:\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.pie(speaker_stats.values, labels=speaker_stats.index, autopct='%1.1f%%')\n",
    "            plt.title('Speaker Time Distribution')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Segment Processing\n",
    "\n",
    "Group segments for efficient API processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Segments already processed\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "{'message': 'column segments.segment_group does not exist', 'code': '42703', 'hint': None, 'details': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ùå Processing error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Show grouping statistics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m segments_data = \u001b[43msupabase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msegments\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msegment_group\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepisode_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.data\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m segments_data:\n\u001b[32m     21\u001b[39m     groups = \u001b[38;5;28mset\u001b[39m(s[\u001b[33m'\u001b[39m\u001b[33msegment_group\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m segments_data \u001b[38;5;28;01mif\u001b[39;00m s.get(\u001b[33m'\u001b[39m\u001b[33msegment_group\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GITHUB/build-vault-embeddings-demo/myenv/lib/python3.13/site-packages/postgrest/_sync/request_builder.py:78\u001b[39m, in \u001b[36mSyncQueryRequestBuilder.execute\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         json_obj = model_validate_json(APIErrorFromJSON, r.content)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m APIError(\u001b[38;5;28mdict\u001b[39m(json_obj))\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIError(generate_default_error_message(r))\n",
      "\u001b[31mAPIError\u001b[39m: {'message': 'column segments.segment_group does not exist', 'code': '42703', 'hint': None, 'details': None}"
     ]
    }
   ],
   "source": [
    "# Process segments\n",
    "if episode_id and segments:\n",
    "    processor = SegmentProcessor()\n",
    "    \n",
    "    # Check if already processed using correct table name\n",
    "    episode_data = supabase.table('podcast_episodes').select('is_processed').eq('id', episode_id).single().execute().data\n",
    "    \n",
    "    if episode_data.get('is_processed') and SKIP_EXISTING:\n",
    "        print(\"‚úÖ Segments already processed\")\n",
    "    else:\n",
    "        print(\"‚úÇÔ∏è Processing segments...\")\n",
    "        try:\n",
    "            processor.process_episode(episode_id)\n",
    "            print(\"‚úÖ Segment processing complete!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Processing error: {e}\")\n",
    "    \n",
    "    # Show grouping statistics\n",
    "    segments_data = supabase.table('segments').select('segment_group').eq('episode_id', episode_id).execute().data\n",
    "    if segments_data:\n",
    "        groups = set(s['segment_group'] for s in segments_data if s.get('segment_group'))\n",
    "        \n",
    "        display(HTML(f\"\"\"\n",
    "        <div style='background: #e8f4f8; padding: 15px; border-radius: 8px;'>\n",
    "            <strong>‚úÇÔ∏è Segment Grouping Results</strong><br>\n",
    "            Total Segments: {len(segments_data)}<br>\n",
    "            Processing Groups: {len(groups)}<br>\n",
    "            Optimization: {((len(segments_data) - len(groups)) / len(segments_data) * 100):.0f}% fewer API calls\n",
    "        </div>\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process segments\n",
    "if episode_id and segments:\n",
    "    processor = SegmentProcessor()\n",
    "    \n",
    "    # Check if already processed using correct table name\n",
    "    episode_data = supabase.table('podcast_episodes').select('is_processed').eq('id', episode_id).single().execute().data\n",
    "    \n",
    "    if episode_data.get('is_processed') and SKIP_EXISTING:\n",
    "        print(\"‚úÖ Segments already processed\")\n",
    "    else:\n",
    "        print(\"‚úÇÔ∏è Processing segments...\")\n",
    "        try:\n",
    "            # Note: segment_group column may not exist in your schema\n",
    "            # The processor tries to group segments but this is optional\n",
    "            processor.process_episode(episode_id)\n",
    "            print(\"‚úÖ Segment processing complete!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Processing error (this is okay if segment_group column doesn't exist): {e}\")\n",
    "            # Try to mark as processed anyway\n",
    "            try:\n",
    "                supabase.table('podcast_episodes').update({\n",
    "                    'is_processed': True\n",
    "                }).eq('id', episode_id).execute()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Show segment statistics without using segment_group\n",
    "    try:\n",
    "        segments_data = supabase.table('segments').select('id').eq('episode_id', episode_id).execute().data\n",
    "        \n",
    "        if segments_data:\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style='background: #e8f4f8; padding: 15px; border-radius: 8px;'>\n",
    "                <strong>‚úÇÔ∏è Segment Processing Results</strong><br>\n",
    "                Total Segments: {len(segments_data)}<br>\n",
    "                Status: Ready for insight extraction<br>\n",
    "                <small style='color: #666;'>Note: Segment grouping is optional and may be skipped if not supported by your schema</small>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not get segment statistics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate episode summary\n",
    "if episode_id:\n",
    "    generator = EpisodeSummaryGenerator()\n",
    "    \n",
    "    # Check existing summary using correct table name\n",
    "    episode_data = supabase.table('podcast_episodes').select('*').eq('id', episode_id).single().execute().data\n",
    "    \n",
    "    # Check if summary already exists in description or a summary field\n",
    "    existing_summary = episode_data.get('summary') or episode_data.get('description')\n",
    "    \n",
    "    if existing_summary and len(existing_summary) > 100 and SKIP_EXISTING:\n",
    "        print(\"‚úÖ Summary already exists\")\n",
    "        summary = existing_summary\n",
    "    else:\n",
    "        print(\"üìù Generating episode summary with GPT-4...\")\n",
    "        try:\n",
    "            summary = generator.generate_summary(episode_id)\n",
    "            print(\"‚úÖ Summary generated!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Summary generation error: {e}\")\n",
    "            summary = existing_summary or \"No summary available\"\n",
    "    \n",
    "    # Display summary\n",
    "    if summary:\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style='background: #f0f8ff; padding: 20px; border-radius: 10px; border: 2px solid #4caf50;'>\n",
    "            <h4 style='color: #2e7d32; margin-top: 0;'>üìù Episode Summary</h4>\n",
    "            <p style='line-height: 1.6;'>{summary[:500]}{'...' if len(summary) > 500 else ''}</p>\n",
    "            <p style='color: #666; font-size: 14px; margin-top: 15px;'>\n",
    "                <strong>Word count:</strong> {len(summary.split())} words\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Insight Extraction\n",
    "\n",
    "Extract categorized insights using Sophisticated Prompts v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract insights\n",
    "insights = []\n",
    "if episode_id:\n",
    "    extractor = InsightExtractor()\n",
    "    \n",
    "    # Check existing insights\n",
    "    existing_insights = supabase.table('insights').select('*').eq('episode_id', episode_id).execute()\n",
    "    \n",
    "    if existing_insights.data and SKIP_EXISTING:\n",
    "        insights = existing_insights.data\n",
    "        print(f\"‚úÖ Found {len(insights)} existing insights\")\n",
    "    else:\n",
    "        print(\"üí° Extracting insights with GPT-4...\")\n",
    "        try:\n",
    "            # Extract insights\n",
    "            extractor.extract_insights_for_episode(episode_id)\n",
    "            \n",
    "            # Get results\n",
    "            insights = supabase.table('insights').select('*').eq('episode_id', episode_id).execute().data\n",
    "            print(f\"‚úÖ Extracted {len(insights)} insights!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Insight extraction error: {e}\")\n",
    "    \n",
    "    # Display insights\n",
    "    if insights:\n",
    "        # Apply demo limit\n",
    "        if DEMO_MODE and MAX_INSIGHTS:\n",
    "            insights = insights[:MAX_INSIGHTS]\n",
    "            print(f\"üìå Demo mode: Showing first {MAX_INSIGHTS} insights\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df_insights = pd.DataFrame(insights)\n",
    "        \n",
    "        # Show insights by category\n",
    "        display(Markdown(\"### üí° Extracted Insights\"))\n",
    "        \n",
    "        categories = df_insights['category'].value_counts()\n",
    "        for category, count in categories.items():\n",
    "            display(HTML(f\"<h4>{category} ({count})</h4>\"))\n",
    "            \n",
    "            cat_insights = df_insights[df_insights['category'] == category].head(3)\n",
    "            for _, insight in cat_insights.iterrows():\n",
    "                display(HTML(f\"\"\"\n",
    "                <div style='background: #f5f5f5; padding: 10px; margin: 5px 0; \n",
    "                            border-left: 3px solid #2196F3;'>\n",
    "                    {insight['content'][:200]}{'...' if len(insight['content']) > 200 else ''}\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "        \n",
    "        # Visualize distribution\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        categories.plot(kind='bar')\n",
    "        plt.title('Insight Distribution by Category')\n",
    "        plt.xlabel('Category')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Product Extraction\n",
    "\n",
    "Identify developer tools and platforms mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract products\n",
    "products = []\n",
    "if episode_id and insights:\n",
    "    product_extractor = ProductExtractor()\n",
    "    \n",
    "    print(\"üì¶ Extracting products from insights...\")\n",
    "    try:\n",
    "        # Extract products\n",
    "        extracted_count = product_extractor.extract_products_from_insights(insights)\n",
    "        print(f\"‚úÖ Extracted {extracted_count} product mentions\")\n",
    "        \n",
    "        # Get unique products\n",
    "        products_result = supabase.table('products').select('*').execute()\n",
    "        products = products_result.data\n",
    "        \n",
    "        # Show products mentioned in this episode\n",
    "        episode_products = []\n",
    "        for product in products:\n",
    "            if episode_id in (product.get('episode_ids') or []):\n",
    "                episode_products.append(product)\n",
    "        \n",
    "        if episode_products:\n",
    "            display(Markdown(\"### üì¶ Products Mentioned\"))\n",
    "            \n",
    "            products_html = \"<div style='display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 15px;'>\"\n",
    "            for product in episode_products[:6]:  # Limit display\n",
    "                products_html += f\"\"\"\n",
    "                <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
    "                            padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
    "                    <h5 style='margin: 0 0 10px 0;'>{product['name']}</h5>\n",
    "                    <p style='color: #666; font-size: 14px; margin: 5px 0;'>\n",
    "                        Mentions: {product.get('mention_count', 1)}\n",
    "                    </p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            products_html += \"</div>\"\n",
    "            display(HTML(products_html))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Product extraction error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Link Processing\n",
    "\n",
    "Extract and enrich links from episode description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process links\n",
    "links = []\n",
    "if episode_id:\n",
    "    link_extractor = LinkExtractor()\n",
    "    link_enricher = LinkEnricher()\n",
    "    \n",
    "    # Check existing links\n",
    "    existing_links = supabase.table('episode_links').select('*').eq('episode_id', episode_id).execute()\n",
    "    \n",
    "    if existing_links.data and SKIP_EXISTING:\n",
    "        links = existing_links.data\n",
    "        print(f\"‚úÖ Found {len(links)} existing links\")\n",
    "    else:\n",
    "        print(\"üîó Extracting links from description...\")\n",
    "        try:\n",
    "            # Extract links\n",
    "            link_extractor.extract_links_for_episode(episode_id)\n",
    "            \n",
    "            # Get extracted links\n",
    "            links = supabase.table('episode_links').select('*').eq('episode_id', episode_id).execute().data\n",
    "            print(f\"‚úÖ Extracted {len(links)} links\")\n",
    "            \n",
    "            # Enrich links (limit for demo)\n",
    "            if links and not DEMO_MODE:\n",
    "                print(\"üîç Enriching links with AI summaries...\")\n",
    "                enriched = link_enricher.enrich_links(limit=3)\n",
    "                print(f\"‚úÖ Enriched {enriched} links\")\n",
    "                \n",
    "                # Refresh links data\n",
    "                links = supabase.table('episode_links').select('*').eq('episode_id', episode_id).execute().data\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Link processing error: {e}\")\n",
    "    \n",
    "    # Display links\n",
    "    if links:\n",
    "        display(Markdown(\"### üîó Episode Links\"))\n",
    "        \n",
    "        for link in links[:5]:  # Limit display\n",
    "            enriched = link.get('enriched', False)\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style='background: #f8f9fa; padding: 15px; margin: 10px 0; \n",
    "                        border-left: 4px solid {'#4caf50' if enriched else '#ff9800'};'>\n",
    "                <a href='{link['url']}' style='color: #2196F3; text-decoration: none;'>\n",
    "                    {link.get('title', link['url'])}\n",
    "                </a>\n",
    "                {f\"<p style='color: #666; margin: 5px 0;'>{link.get('description', '')}</p>\" if link.get('description') else ''}\n",
    "                <span style='background: {'#e8f5e9' if enriched else '#fff3e0'}; \n",
    "                             color: {'#4caf50' if enriched else '#ff9800'}; \n",
    "                             padding: 2px 8px; border-radius: 3px; font-size: 12px;'>\n",
    "                    {'‚úì Enriched' if enriched else '‚óã Pending'}\n",
    "                </span>\n",
    "            </div>\n",
    "            \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Embeddings\n",
    "\n",
    "Create vector embeddings for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "if episode_id and not DEMO_MODE:  # Skip in demo to save costs\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    \n",
    "    print(\"üî¢ Generating vector embeddings...\")\n",
    "    \n",
    "    try:\n",
    "        embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "        \n",
    "        # Check what needs embeddings - use correct column names\n",
    "        segments_need = supabase.table('segments').select('id, raw_text, display_text').eq('episode_id', episode_id).is_('embedding', 'null').execute().data\n",
    "        insights_need = supabase.table('insights').select('id, content').eq('episode_id', episode_id).is_('embedding', 'null').execute().data\n",
    "        \n",
    "        total_needed = len(segments_need) + len(insights_need)\n",
    "        \n",
    "        if total_needed > 0:\n",
    "            print(f\"üìä Need to generate embeddings for:\")\n",
    "            print(f\"   - {len(segments_need)} segments\")\n",
    "            print(f\"   - {len(insights_need)} insights\")\n",
    "            \n",
    "            # Generate segment embeddings (batch for efficiency)\n",
    "            if segments_need:\n",
    "                # Use display_text if available, otherwise raw_text\n",
    "                texts = []\n",
    "                for s in segments_need[:5]:  # Limit for demo\n",
    "                    text = s.get('display_text') or s.get('raw_text', '')\n",
    "                    texts.append(text)\n",
    "                \n",
    "                vectors = embeddings_model.embed_documents(texts)\n",
    "                \n",
    "                # Update database\n",
    "                for i, (segment, vector) in enumerate(zip(segments_need[:5], vectors)):\n",
    "                    supabase.table('segments').update({\n",
    "                        'embedding': vector\n",
    "                    }).eq('id', segment['id']).execute()\n",
    "                \n",
    "                print(f\"‚úÖ Generated embeddings for {len(vectors)} segments\")\n",
    "            \n",
    "            # Generate insight embeddings\n",
    "            if insights_need:\n",
    "                texts = [i['content'] for i in insights_need[:5]]  # Limit for demo\n",
    "                vectors = embeddings_model.embed_documents(texts)\n",
    "                \n",
    "                # Update database\n",
    "                for i, (insight, vector) in enumerate(zip(insights_need[:5], vectors)):\n",
    "                    supabase.table('insights').update({\n",
    "                        'embedding': vector\n",
    "                    }).eq('id', insight['id']).execute()\n",
    "                \n",
    "                print(f\"‚úÖ Generated embeddings for {len(vectors)} insights\")\n",
    "        else:\n",
    "            print(\"‚úÖ All items already have embeddings\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Embedding error: {e}\")\n",
    "else:\n",
    "    if DEMO_MODE:\n",
    "        display(HTML(\"\"\"\n",
    "        <div style='background: #fff3cd; padding: 15px; border-radius: 5px;'>\n",
    "            <strong>‚ö†Ô∏è Embeddings skipped in demo mode</strong><br>\n",
    "            In production, this step generates 3072-dimensional vectors for semantic search.\n",
    "        </div>\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Summary\n",
    "\n",
    "Review the complete processing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary\n",
    "if episode_id:\n",
    "    # Gather statistics\n",
    "    stats = {\n",
    "        \"Episode\": episode_data.get('title', 'Unknown'),\n",
    "        \"Duration\": f\"{episode_data.get('duration', 0)} seconds\",\n",
    "        \"Segments\": len(segments),\n",
    "        \"Insights\": len(insights),\n",
    "        \"Products\": len([p for p in products if episode_id in (p.get('episode_ids') or [])]),\n",
    "        \"Links\": len(links),\n",
    "        \"Status\": episode_data.get('status', 'Unknown')\n",
    "    }\n",
    "    \n",
    "    # Create summary dashboard\n",
    "    display(Markdown(\"## üéâ Pipeline Complete!\"))\n",
    "    \n",
    "    stats_html = \"\"\"\n",
    "    <div style='display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); \n",
    "                gap: 15px; margin: 20px 0;'>\n",
    "    \"\"\"\n",
    "    \n",
    "    colors = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c', '#9b59b6', '#1abc9c', '#34495e']\n",
    "    \n",
    "    for i, (stat, value) in enumerate(stats.items()):\n",
    "        color = colors[i % len(colors)]\n",
    "        stats_html += f\"\"\"\n",
    "        <div style='background: {color}; color: white; padding: 20px; \n",
    "                    border-radius: 10px; text-align: center;'>\n",
    "            <div style='font-size: 24px; font-weight: bold;'>{value}</div>\n",
    "            <div style='font-size: 14px; margin-top: 5px;'>{stat}</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    stats_html += \"</div>\"\n",
    "    display(HTML(stats_html))\n",
    "    \n",
    "    # Show next steps\n",
    "    display(Markdown(\"\"\"\n",
    "### üöÄ Next Steps\n",
    "\n",
    "1. **View in Web Interface**: \n",
    "   ```bash\n",
    "   cd ../web && uv run python app.py\n",
    "   ```\n",
    "   Then visit http://localhost:8000\n",
    "\n",
    "2. **Search Insights**: Use the web interface to search across all extracted insights\n",
    "\n",
    "3. **Browse Products**: View all mentioned developer tools in the products directory\n",
    "\n",
    "4. **API Access**: Query the data via FastAPI endpoints\n",
    "\n",
    "### üí° Tips\n",
    "\n",
    "- Set `DEMO_MODE = False` to process complete episodes\n",
    "- Use `SKIP_EXISTING = True` to avoid reprocessing\n",
    "- Check LangSmith for detailed traces of AI operations\n",
    "- Monitor costs in your OpenAI dashboard\n",
    "    \"\"\"))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No episode was processed. Check the configuration and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Estimation\n",
    "\n",
    "Estimate the API costs for this processing run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate costs (rough approximation)\n",
    "if episode_id:\n",
    "    # Cost estimates (as of 2024)\n",
    "    costs = {\n",
    "        \"AssemblyAI Transcription\": 0.00025 * episode_data.get('duration', 0),  # $0.00025/second\n",
    "        \"GPT-4 Summary\": 0.03 * 0.5,  # ~500 tokens in, 250 out\n",
    "        \"GPT-4 Insights\": 0.03 * len(segments) * 0.3,  # Rough estimate\n",
    "        \"Embeddings\": 0.00013 * (len(segments) + len(insights)),  # $0.13 per 1M tokens\n",
    "        \"Total\": 0\n",
    "    }\n",
    "    \n",
    "    costs[\"Total\"] = sum(v for k, v in costs.items() if k != \"Total\")\n",
    "    \n",
    "    display(Markdown(\"### üí∞ Estimated API Costs\"))\n",
    "    \n",
    "    cost_html = \"<table style='width: 100%; border-collapse: collapse;'>\"\n",
    "    cost_html += \"<tr style='background: #f5f5f5;'><th style='padding: 10px; text-align: left;'>Service</th><th style='padding: 10px; text-align: right;'>Estimated Cost</th></tr>\"\n",
    "    \n",
    "    for service, cost in costs.items():\n",
    "        style = \"font-weight: bold; background: #e8f5e9;\" if service == \"Total\" else \"\"\n",
    "        cost_html += f\"<tr style='{style}'><td style='padding: 10px;'>{service}</td><td style='padding: 10px; text-align: right;'>${cost:.4f}</td></tr>\"\n",
    "    \n",
    "    cost_html += \"</table>\"\n",
    "    display(HTML(cost_html))\n",
    "    \n",
    "    display(HTML(\"\"\"\n",
    "    <p style='color: #666; font-size: 14px; margin-top: 10px;'>\n",
    "        <strong>Note:</strong> These are rough estimates. Actual costs may vary based on token usage and current pricing.\n",
    "    </p>\n",
    "    \"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Build Vault (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
