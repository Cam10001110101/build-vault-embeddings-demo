{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv langchain langchain_core langchain-community langchain-chroma ipywidgets umap-learn pandas chromadb openai langchain-openai yt-dlp assemblyai matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import chromadb\n",
    "import openai\n",
    "import langchain_openai\n",
    "import yt_dlp\n",
    "import assemblyai\n",
    "import dotenv\n",
    "import pandas\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Markdown, clear_output\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Configure Visualization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure visualization\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pipeline configuration\n",
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline configuration\n",
    "config_path = os.path.join(os.getcwd(), 'pipeline_config.json')\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"Loaded pipeline configuration\")\n",
    "else:\n",
    "    print(\"Warning: pipeline_config.json not found, using defaults\")\n",
    "    config = {}\n",
    "\n",
    "print(config.get('messages', {}).get('import_complete', 'Imports complete'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from dotenv import load_dotenv\nimport os\n\n# Load .env file if it exists\nload_dotenv()\n\n# For Google Colab, you may need to set environment variables directly\n# Option 1: Set them directly in the notebook\n# os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n# os.environ['ASSEMBLYAI_API_KEY'] = 'your-assemblyai-key-here'\n# os.environ['YOUTUBE_API_KEY'] = 'your-youtube-api-key-here'\n\n# Option 2: Use Google Colab secrets (recommended)\n# In Colab, go to the key icon on the left sidebar and add your secrets\n\n# Option 3: Upload your .env file to Colab and load it\n# from google.colab import files\n# uploaded = files.upload()  # Upload your .env file\n# load_dotenv('.env')\n\nrequired = ('YOUTUBE_API_KEY', 'ASSEMBLYAI_API_KEY', 'OPENAI_API_KEY')\nmissing  = [var for var in required if not os.getenv(var)]\n\nif missing:\n    print(f\"Missing env vars: {', '.join(missing)}\")\n    print(\"\\nFor Google Colab, you can:\")\n    print(\"1. Set them directly: os.environ['OPENAI_API_KEY'] = 'your-key'\")\n    print(\"2. Use Colab secrets (recommended): Click the key icon in the left sidebar\")\n    print(\"3. Upload your .env file using the code above\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create local data storage (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), config.get('data_directory', '.'))\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "json_files = {\n",
    "    k: os.path.join(DATA_DIR, fname)\n",
    "    for k, fname in config.get('data_files', {}).items()\n",
    "}\n",
    "\n",
    "for path in json_files.values():\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump([], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChromaDB...\n",
      "ChromaDB initialized successfully!\n",
      "  - Segments collection: 0 items\n",
      "  - Insights collection: 0 items\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing ChromaDB...\")\n",
    "\n",
    "# Create ChromaDB directory\n",
    "CHROMA_DIR = os.path.join(DATA_DIR, 'chromadb')\n",
    "os.makedirs(CHROMA_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize ChromaDB client with persistent storage\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "\n",
    "# Create embedding function using OpenAI\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    model_name=config.get('semantic_search', {}).get('embedding_model', os.getenv('EMBEDDING_MODEL', 'text-embedding-3-small'))\n",
    ")\n",
    "\n",
    "# Create or get collections for segments and insights\n",
    "try:\n",
    "    segments_collection = chroma_client.get_or_create_collection(\n",
    "        name=\"segments\",\n",
    "        embedding_function=openai_ef,\n",
    "        metadata={\"description\": \"Episode transcript segments\"}\n",
    "    )\n",
    "    \n",
    "    insights_collection = chroma_client.get_or_create_collection(\n",
    "        name=\"insights\",\n",
    "        embedding_function=openai_ef,\n",
    "        metadata={\"description\": \"Extracted episode insights\"}\n",
    "    )\n",
    "    \n",
    "    print(f\"ChromaDB initialized successfully!\")\n",
    "    print(f\"  - Segments collection: {segments_collection.count()} items\")\n",
    "    print(f\"  - Insights collection: {insights_collection.count()} items\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing ChromaDB: {e}\")\n",
    "    segments_collection = None\n",
    "    insights_collection = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Audio Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading audio from: https://www.youtube.com/watch?v=Y0KB8FsbCKc&t=529s\n",
      "Downloaded: The Build - LangChain Open Deep Research       \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import yt_dlp\n",
    "\n",
    "# Configuration\n",
    "YOUTUBE_URL = os.getenv('YOUTUBE_URL')\n",
    "\n",
    "# Extract video ID\n",
    "video_id = YOUTUBE_URL.split('v=')[-1].split('&')[0]\n",
    "audio_dir = os.path.join(os.getcwd(), config.get('audio_directory', 'audio_storage'))\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "# Check if episode exists\n",
    "with open(json_files['episodes'], 'r') as f:\n",
    "    episodes_data = json.load(f)\n",
    "existing = [ep for ep in episodes_data if ep['youtube_video_id'] == video_id]\n",
    "\n",
    "# Always download, regardless of whether episode exists\n",
    "print(f\"{config.get('messages', {}).get('downloading_audio', 'Downloading audio from:')} {YOUTUBE_URL}\")\n",
    "\n",
    "# Download with yt-dlp\n",
    "output_path = os.path.join(audio_dir, f'{video_id}.mp3')\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl': output_path.replace('.mp3', '.%(ext)s'),\n",
    "    'quiet': True,\n",
    "    'no_warnings': True,\n",
    "}\n",
    "\n",
    "try:\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(YOUTUBE_URL, download=True)\n",
    "        \n",
    "    # Create episode record\n",
    "    episode_id = str(uuid.uuid4())\n",
    "    episode_data = {\n",
    "        'id': episode_id,\n",
    "        'title': info.get('title', 'Unknown Title'),\n",
    "        'youtube_video_id': video_id,\n",
    "        'youtube_url': YOUTUBE_URL,\n",
    "        'duration': info.get('duration', 0),\n",
    "        'published_at': datetime.now().isoformat(),\n",
    "        'status': 'downloaded',\n",
    "        'audio_file_path': output_path,\n",
    "        'summary': '',\n",
    "        'is_processed': False\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    episodes_data.append(episode_data)\n",
    "    with open(json_files['episodes'], 'w') as f:\n",
    "        json.dump(episodes_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Downloaded: {episode_data['title']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Download error: {e}\")\n",
    "    episode_id = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display episode info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Info:\n",
      "  Title: The Build - LangChain Open Deep Research\n",
      "  YouTube ID: Y0KB8FsbCKc\n",
      "  Duration: 1608 s\n",
      "  Status: downloaded\n"
     ]
    }
   ],
   "source": [
    "if episode_id:                      \n",
    "    print(\n",
    "        f\"Episode Info:\\n\"\n",
    "        f\"  Title: {episode_data['title']}\\n\"\n",
    "        f\"  YouTube ID: {video_id}\\n\"\n",
    "        f\"  Duration: {episode_data['duration']} s\\n\"\n",
    "        f\"  Status: {episode_data['status']}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Failed to download or load episode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed.\n"
     ]
    }
   ],
   "source": [
    "import os, json, uuid, assemblyai as aai\n",
    "\n",
    "if not episode_id:                               # ensure download step ran\n",
    "    raise RuntimeError(\"episode_id missing\")\n",
    "\n",
    "with open(json_files['segments']) as f:          # load existing segments\n",
    "    all_segments = json.load(f)\n",
    "\n",
    "segments = [s for s in all_segments if s['episode_id'] == episode_id]\n",
    "\n",
    "if not segments:                                 # need to transcribe\n",
    "    aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "    tr = aai.Transcriber().transcribe(\n",
    "        episode_data['audio_file_path'],\n",
    "        config=aai.TranscriptionConfig(speaker_labels=True, speakers_expected=2),\n",
    "    )\n",
    "    if tr.status == aai.TranscriptStatus.error:\n",
    "        raise RuntimeError(f\"AssemblyAI: {tr.error}\")\n",
    "\n",
    "    segments = [\n",
    "        {\n",
    "            'id': str(uuid.uuid4()),\n",
    "            'episode_id': episode_id,\n",
    "            'start_time': u.start / 1000,\n",
    "            'end_time':  u.end   / 1000,\n",
    "            'raw_text':  u.text,\n",
    "            'display_text': u.text,\n",
    "            'speaker': f\"Speaker {u.speaker}\",\n",
    "            'confidence': getattr(u, 'confidence', 0.9),\n",
    "            'duration': (u.end - u.start) / 1000,\n",
    "        }\n",
    "        for u in tr.utterances\n",
    "    ]\n",
    "    all_segments.extend(segments)\n",
    "    with open(json_files['segments'], 'w') as f:\n",
    "        json.dump(all_segments, f, indent=2)\n",
    "\n",
    "    print(\"Transcription completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments: 92\n",
      "Total insights extracted: 0\n",
      "Success: saved 0 insights to JSON.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/_69v8t_d6k94phbfc_2y962w0000gn/T/ipykernel_43985/780309293.py\", line 24, in <module>\n",
      "    resp = client.chat.completions.create(\n",
      "        model=os.getenv('LLM_MODEL'),\n",
      "    ...<4 lines>...\n",
      "        temperature=0.1\n",
      "    )\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1256, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/openai/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `qwen3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n"
     ]
    }
   ],
   "source": [
    "import os, json, uuid, traceback\n",
    "from openai import OpenAI\n",
    "import assemblyai as aai   # if still needed elsewhere\n",
    "\n",
    "if not episode_id or not segments:\n",
    "    raise RuntimeError(\"Missing episode_id or segments—run previous steps first.\")\n",
    "\n",
    "SEGMENT_COUNT = len(segments)\n",
    "INSIGHT_BATCH = config.get('processing', {}).get('transcript_batch_size', 10)\n",
    "MAX_BATCHES   = config.get('processing', {}).get('max_transcript_batches', 10)\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "with open(json_files['insights']) as f:\n",
    "    all_insights = json.load(f)\n",
    "\n",
    "new_insights = []\n",
    "\n",
    "for i in range(0, min(SEGMENT_COUNT, INSIGHT_BATCH * MAX_BATCHES), INSIGHT_BATCH):\n",
    "    batch = segments[i : i + INSIGHT_BATCH]\n",
    "    transcript = \"\\n\".join(f\"{s['speaker']}: {s['display_text']}\" for s in batch)[:3500]\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=os.getenv('LLM_MODEL'),\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": config.get('llm_prompts', {}).get('insight_extraction', '')},\n",
    "                {\"role\": \"user\",   \"content\": f\"Extract insights from this podcast segment:\\n\\n{transcript}\"}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        batch_data = json.loads(resp.choices[0].message.content).get('insights', [])\n",
    "        for ins in batch_data:\n",
    "            if ins.get('content'):\n",
    "                new_insights.append({\n",
    "                    'id': str(uuid.uuid4()),\n",
    "                    'episode_id': episode_id,\n",
    "                    'category': ins.get('category', 'Business Ideas'),\n",
    "                    'content': ins['content'],\n",
    "                    'confidence_score': float(ins.get('confidence', 0.8)),\n",
    "                    'segment_start': batch[0]['start_time'],\n",
    "                    'segment_end':   batch[-1]['end_time'],\n",
    "                })\n",
    "    except Exception:          # JSON errors, API errors, etc.\n",
    "        traceback.print_exc()   # optional: comment out to silence\n",
    "\n",
    "# save if any new insights\n",
    "if new_insights:\n",
    "    all_insights.extend(new_insights)\n",
    "    with open(json_files['insights'], 'w') as f:\n",
    "        json.dump(all_insights, f, indent=2)\n",
    "\n",
    "print(f\"Segments: {SEGMENT_COUNT}\")\n",
    "print(f\"Total insights extracted: {len(new_insights)}\")\n",
    "print(f\"Success: saved {len(new_insights)} insights to JSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No insights to display. Check the debug output above.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'insights' in locals() and insights:\n",
    "    display_insights = insights\n",
    "    \n",
    "    display(Markdown(\"### Extracted Insights\"))\n",
    "    \n",
    "    # Group by category\n",
    "    df_insights = pd.DataFrame(display_insights)\n",
    "    categories = df_insights['category'].value_counts()\n",
    "    \n",
    "    print(f\"\\nInsights by category:\")\n",
    "    for category, count in categories.items():\n",
    "        print(f\"   {category}: {count}\")\n",
    "    \n",
    "    # Display insights by category\n",
    "    for category, count in categories.items():\n",
    "        display(HTML(f\"<h4>{category} ({count})</h4>\"))\n",
    "        \n",
    "        cat_insights = df_insights[df_insights['category'] == category].head(3)\n",
    "        for _, insight in cat_insights.iterrows():\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style='background: #f5f5f5; padding: 10px; margin: 5px 0; \n",
    "                        border-left: 3px solid #2196F3; border-radius: 5px;'>\n",
    "                <p style='margin: 0;'>{insight['content']}</p>\n",
    "                <small style='color: #666;'>Confidence: {insight['confidence_score']:.2f}</small>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "    \n",
    "    # Visualize distribution\n",
    "    if not categories.empty:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        categories.plot(kind='bar')\n",
    "        plt.title('Insight Distribution by Category')\n",
    "        plt.xlabel('Category')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"\\nNo insights to display. Check the debug output above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting products from episode content...\n",
      "Searching for 501 known products...\n",
      "\n",
      "Checking 92 transcript segments...\n",
      "\n",
      "Found 78 total product mentions\n",
      "24 unique products found\n",
      "Success: Added 24 new products to database\n",
      "\n",
      "Success: Products extraction complete!\n",
      "   - Total unique products: 24\n",
      "   - Total mentions: 78\n"
     ]
    }
   ],
   "source": [
    "# Extract products mentioned\n",
    "print(config.get('messages', {}).get('extracting_products', 'Extracting products from episode content...'))\n",
    "\n",
    "# Check if we have data to work with\n",
    "has_insights = 'insights' in locals() and insights\n",
    "has_segments = 'segments' in locals() and segments\n",
    "\n",
    "if not has_segments:\n",
    "    print(\"Error: No segments available. Please run transcription first.\")\n",
    "else:\n",
    "    # Read existing products\n",
    "    with open(json_files['products'], 'r') as f:\n",
    "        products_data = json.load(f)\n",
    "    products_found = []\n",
    "    \n",
    "    # Get known products from config\n",
    "    known_products = config.get('known_products', [])\n",
    "    \n",
    "    print(f\"Searching for {len(known_products)} known products...\")\n",
    "    \n",
    "    # Extract from insights if available\n",
    "    if has_insights:\n",
    "        print(\"\\nChecking insights for product mentions...\")\n",
    "        for insight in insights:\n",
    "            content = insight['content'].lower()\n",
    "            \n",
    "            for product in known_products:\n",
    "                if product.lower() in content:\n",
    "                    products_found.append({\n",
    "                        'name': product,\n",
    "                        'episode_id': episode_id,\n",
    "                        'mentioned_in': 'insight',\n",
    "                        'context': insight['content'][:200]\n",
    "                    })\n",
    "    \n",
    "    # Extract from transcript segments\n",
    "    demo_limit = config.get('processing', {}).get('demo_segment_limit', 50)\n",
    "    print(f\"\\nChecking {min(len(segments), demo_limit)} transcript segments...\")\n",
    "    for i, segment in enumerate(segments[:demo_limit]):\n",
    "        content = segment['display_text'].lower()\n",
    "        \n",
    "        for product in known_products:\n",
    "            if product.lower() in content:\n",
    "                products_found.append({\n",
    "                    'name': product,\n",
    "                    'episode_id': episode_id,\n",
    "                    'mentioned_in': 'transcript',\n",
    "                    'context': segment['display_text'][:200]\n",
    "                })\n",
    "    \n",
    "    print(f\"\\nFound {len(products_found)} total product mentions\")\n",
    "    \n",
    "    # Deduplicate and count mentions\n",
    "    product_counts = {}\n",
    "    for p in products_found:\n",
    "        name = p['name']\n",
    "        if name not in product_counts:\n",
    "            product_counts[name] = {\n",
    "                'count': 0,\n",
    "                'episode_ids': [],\n",
    "                'contexts': []\n",
    "            }\n",
    "        product_counts[name]['count'] += 1\n",
    "        if episode_id not in product_counts[name]['episode_ids']:\n",
    "            product_counts[name]['episode_ids'].append(episode_id)\n",
    "        product_counts[name]['contexts'].append(p['context'])\n",
    "    \n",
    "    print(f\"{len(product_counts)} unique products found\")\n",
    "    \n",
    "    # Update products data\n",
    "    new_products = []\n",
    "    updated_count = 0\n",
    "    \n",
    "    for name, data in product_counts.items():\n",
    "        # Check if product already exists\n",
    "        existing = next((p for p in products_data if p['name'] == name), None)\n",
    "        \n",
    "        if not existing:\n",
    "            # New product\n",
    "            new_products.append({\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'name': name,\n",
    "                'episode_ids': data['episode_ids'],\n",
    "                'mention_count': data['count']\n",
    "            })\n",
    "        else:\n",
    "            # Update existing product\n",
    "            if episode_id not in existing['episode_ids']:\n",
    "                existing['episode_ids'].append(episode_id)\n",
    "            existing['mention_count'] += data['count']\n",
    "            updated_count += 1\n",
    "    \n",
    "    # Add new products\n",
    "    if new_products:\n",
    "        products_data.extend(new_products)\n",
    "        print(f\"Success: Added {len(new_products)} new products to database\")\n",
    "    \n",
    "    if updated_count:\n",
    "        print(f\"Success: Updated {updated_count} existing products\")\n",
    "    \n",
    "    # Save to JSON\n",
    "    with open(json_files['products'], 'w') as f:\n",
    "        json.dump(products_data, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nSuccess: Products extraction complete!\")\n",
    "    print(f\"   - Total unique products: {len(product_counts)}\")\n",
    "    print(f\"   - Total mentions: {sum(p['count'] for p in product_counts.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Products Mentioned"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Top Products by Mentions:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                1. IO \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    37 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"Yeah, they're really good about when like OpenAI or someone comes out with something that makes a big splash, they turn around and create like an open source version of it....\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                2. Flow \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    7 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"I think what's really cool about this for demonstration is that it's not just one pattern necessarily. There are three different designs here. So you can see that I've got it broken up by workflows an...\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                3. OpenAI \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    5 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"Yeah, they're really good about when like OpenAI or someone comes out with something that makes a big splash, they turn around and create like an open source version of it....\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                4. Claude \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    3 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"Pretty much the open version, yeah. So whenever there's like they did with computer use, like the demo that I showed you a couple of months, a couple of weeks back. This one is basically a replication...\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                5. Anthropic \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    3 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"Yeah. So while that's running, I just started a new session here, but you can see if you spin this up and then you select your graph that you want to work with, then down here, this, this button that ...\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                6. LangChain \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    2 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"I would love for you to talk me through this because this is pretty relevant. So this is an, an open source project that they've published relatively recently, the LangChain guys. And when they do thi...\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                7. ChatGPT \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    2 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"Pretty much the open version, yeah. So whenever there's like they did with computer use, like the demo that I showed you a couple of months, a couple of weeks back. This one is basically a replication...\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                8. Langgraph \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    2 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"Well, that's the cool part is you don't have to spin up different. It's all part of the same. Well, they're, they're separate graphs, but it's all the same application. When I run langgraph Dev, we ha...\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                9. LangGraph \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    2 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"Well, that's the cool part is you don't have to spin up different. It's all part of the same. Well, they're, they're separate graphs, but it's all the same application. When I run langgraph Dev, we ha...\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
       "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
       "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
       "                10. Computer Use \n",
       "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
       "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
       "                    1 mentions\n",
       "                </span>\n",
       "            </h5>\n",
       "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
       "                \"Pretty much the open version, yeah. So whenever there's like they did with computer use, like the demo that I showed you a couple of months, a couple of weeks back. This one is basically a replication...\"\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Product Mention Distribution:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if product_counts:\n",
    "    display(Markdown(\"### Products Mentioned\"))\n",
    "    \n",
    "    # Sort by mention count\n",
    "    sorted_products = sorted(product_counts.items(), key=lambda x: x[1]['count'], reverse=True)\n",
    "    \n",
    "    # Show top products with context\n",
    "    display(Markdown(\"#### Top Products by Mentions:\"))\n",
    "    for i, (name, data) in enumerate(sorted_products[:10]):\n",
    "        # Get a sample context\n",
    "        sample_context = data['contexts'][0] if data['contexts'] else \"No context available\"\n",
    "        \n",
    "        display(HTML(f\"\"\"\n",
    "        <div style='background: white; border: 1px solid #e0e0e0; border-radius: 8px; \n",
    "                    padding: 15px; margin: 10px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>\n",
    "            <h5 style='margin: 0 0 10px 0; color: #333;'>\n",
    "                {i+1}. {name} \n",
    "                <span style='background: #2196F3; color: white; padding: 2px 8px; \n",
    "                            border-radius: 12px; font-size: 12px; margin-left: 10px;'>\n",
    "                    {data['count']} mentions\n",
    "                </span>\n",
    "            </h5>\n",
    "            <p style='color: #666; font-size: 14px; margin: 0; font-style: italic;'>\n",
    "                \"{sample_context}...\"\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "    \n",
    "    # Product cloud visualization\n",
    "    if len(sorted_products) > 5:\n",
    "        display(Markdown(\"#### Product Mention Distribution:\"))\n",
    "        \n",
    "        # Create bar chart\n",
    "        top_10 = sorted_products[:10]\n",
    "        names = [p[0] for p in top_10]\n",
    "        counts = [p[1]['count'] for p in top_10]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(names, counts, color='#2196F3')\n",
    "        plt.title('Top 10 Products by Mention Count')\n",
    "        plt.xlabel('Product')\n",
    "        plt.ylabel('Number of Mentions')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"\\nNo products found. This could be because:\")\n",
    "    print(\"   - The episode doesn't mention any known products\")\n",
    "    print(\"   - The transcript is too short\")\n",
    "    print(\"   - The product list needs to be expanded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract links, insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting links from episode content...\n",
      "Searching for links in available content...\n",
      "\n",
      "Checking 30 transcript segments for links...\n",
      "\n",
      "Checking for mentioned websites...\n",
      "\n",
      "Found 3 total link mentions\n",
      "3 unique links after deduplication\n",
      "\n",
      "Success: Saved 3 new links to JSON\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "print(config.get('messages', {}).get('extracting_links', 'Extracting links from episode content...'))\n",
    "\n",
    "if 'episode_id' not in locals():\n",
    "    print(\"Error: Please run the Audio Download step first\")\n",
    "else:\n",
    "    # Read existing links\n",
    "    with open(json_files['links'], 'r') as f:\n",
    "        links_data = json.load(f)\n",
    "    found_links = []\n",
    "    \n",
    "    # Enhanced URL pattern to catch more URL formats\n",
    "    url_patterns = [\n",
    "        re.compile(r'https?://(?:www\\.)?[^\\s<>\"{}|\\\\^`\\[\\]]+'),\n",
    "        re.compile(r'(?:www\\.)[^\\s<>\"{}|\\\\^`\\[\\]]+\\.[a-z]{2,}'),\n",
    "        re.compile(r'[a-zA-Z0-9-]+\\.[a-z]{2,}/[^\\s<>\"{}|\\\\^`\\[\\]]*')\n",
    "    ]\n",
    "    \n",
    "    print(\"Searching for links in available content...\")\n",
    "    \n",
    "    # Extract from insights\n",
    "    if 'insights' in locals() and insights:\n",
    "        print(f\"\\nChecking {len(insights)} insights for links...\")\n",
    "        for insight in insights:\n",
    "            for pattern in url_patterns:\n",
    "                urls = pattern.findall(insight['content'])\n",
    "                for url in urls:\n",
    "                    # Normalize URL\n",
    "                    if not url.startswith('http'):\n",
    "                        url = 'https://' + url\n",
    "                    found_links.append({\n",
    "                        'url': url,\n",
    "                        'source': 'insight',\n",
    "                        'context': insight['content'][:150]\n",
    "                    })\n",
    "    \n",
    "    # Extract from transcript\n",
    "    if 'segments' in locals() and segments:\n",
    "        print(f\"\\nChecking {min(len(segments), 30)} transcript segments for links...\")\n",
    "        for segment in segments[:30]:  # Check first 30 segments\n",
    "            for pattern in url_patterns:\n",
    "                urls = pattern.findall(segment['display_text'])\n",
    "                for url in urls:\n",
    "                    if not url.startswith('http'):\n",
    "                        url = 'https://' + url\n",
    "                    found_links.append({\n",
    "                        'url': url,\n",
    "                        'source': 'transcript',\n",
    "                        'context': segment['display_text'][:150]\n",
    "                    })\n",
    "    \n",
    "    # Get website mentions from config\n",
    "    print(\"\\nChecking for mentioned websites...\")\n",
    "    website_mentions = config.get('website_mentions', {})\n",
    "    \n",
    "    # Search in all available text\n",
    "    all_text = \"\"\n",
    "    if 'segments' in locals() and segments:\n",
    "        all_text += \" \".join([s['display_text'] for s in segments[:50]])\n",
    "    if 'insights' in locals() and insights:\n",
    "        all_text += \" \".join([i['content'] for i in insights])\n",
    "    \n",
    "    all_text_lower = all_text.lower()\n",
    "    \n",
    "    for mention, url in website_mentions.items():\n",
    "        if mention in all_text_lower:\n",
    "            found_links.append({\n",
    "                'url': url,\n",
    "                'source': 'inferred',\n",
    "                'context': f'{mention.title()} was mentioned in the episode'\n",
    "            })\n",
    "    \n",
    "    print(f\"\\nFound {len(found_links)} total link mentions\")\n",
    "    \n",
    "    # Deduplicate links\n",
    "    unique_links = {}\n",
    "    for link in found_links:\n",
    "        url = link['url'].rstrip('/').lower()  # Normalize URL\n",
    "        if url not in unique_links:\n",
    "            unique_links[url] = link\n",
    "    \n",
    "    print(f\"{len(unique_links)} unique links after deduplication\")\n",
    "    \n",
    "    # Create link records\n",
    "    new_links = []\n",
    "    for url, link_data in unique_links.items():\n",
    "        # Check if link already exists for this episode\n",
    "        existing = next((l for l in links_data if l['episode_id'] == episode_id and l['url'] == link_data['url']), None)\n",
    "        \n",
    "        if not existing:\n",
    "            # Extract title from URL\n",
    "            url_parts = link_data['url'].replace('https://', '').replace('http://', '').split('/')\n",
    "            domain = url_parts[0].replace('www.', '')\n",
    "            title = domain.split('.')[0].title() if domain else 'Link'\n",
    "            \n",
    "            # Better title extraction\n",
    "            if 'github.com' in link_data['url']:\n",
    "                title = 'GitHub: ' + '/'.join(url_parts[1:3]) if len(url_parts) > 2 else 'GitHub'\n",
    "            elif 'youtube.com' in link_data['url'] or 'youtu.be' in link_data['url']:\n",
    "                title = 'YouTube Video'\n",
    "            elif link_data['source'] == 'inferred':\n",
    "                title = link_data['context']\n",
    "            \n",
    "            new_links.append({\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'episode_id': episode_id,\n",
    "                'url': link_data['url'],\n",
    "                'title': title,\n",
    "                'description': f\"Found in {link_data['source']}: {link_data['context']}\",\n",
    "                'enriched': False\n",
    "            })\n",
    "    \n",
    "    # Add new links\n",
    "    if new_links:\n",
    "        links_data.extend(new_links)\n",
    "        with open(json_files['links'], 'w') as f:\n",
    "            json.dump(links_data, f, indent=2)\n",
    "        print(f\"\\nSuccess: Saved {len(new_links)} new links to JSON\")\n",
    "    else:\n",
    "        print(\"\\nNo new links found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embeddings and store in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vector embeddings...\n",
      "Need to generate embeddings for:\n",
      "   - 92 new segments\n",
      "\n",
      "Adding segments to ChromaDB...\n",
      "   Processing batch 1/19...\n",
      "   Processing batch 2/19...\n",
      "   Processing batch 3/19...\n",
      "   Processing batch 4/19...\n",
      "   Processing batch 5/19...\n",
      "   Processing batch 6/19...\n",
      "   Processing batch 7/19...\n",
      "   Processing batch 8/19...\n",
      "   Processing batch 9/19...\n",
      "   Processing batch 10/19...\n",
      "   Processing batch 11/19...\n",
      "   Processing batch 12/19...\n",
      "   Processing batch 13/19...\n",
      "   Processing batch 14/19...\n",
      "   Processing batch 15/19...\n",
      "   Processing batch 16/19...\n",
      "   Processing batch 17/19...\n",
      "   Processing batch 18/19...\n",
      "   Processing batch 19/19...\n",
      "Success: Added 92 segments to ChromaDB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='background: #e8f5e9; padding: 15px; border-radius: 5px; margin-top: 10px;'>\n",
       "                <strong>ChromaDB Embeddings Update Complete!</strong><br>\n",
       "                <ul style='margin: 5px 0;'>\n",
       "                    <li>New segments added: 92</li>\n",
       "                    <li>New insights added: 0</li>\n",
       "                    <li>Total segments in DB: 92</li>\n",
       "                    <li>Total insights in DB: 0</li>\n",
       "                </ul>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if episode_id and segments_collection and insights_collection:\n",
    "    print(config.get('messages', {}).get('generating_embeddings', 'Generating vector embeddings and storing in ChromaDB...'))\n",
    "    \n",
    "    try:\n",
    "        # Load segments and insights\n",
    "        with open(json_files['segments'], 'r') as f:\n",
    "            segments_data = json.load(f)\n",
    "        with open(json_files['insights'], 'r') as f:\n",
    "            insights_data = json.load(f)\n",
    "        \n",
    "        # Filter for current episode\n",
    "        episode_segments = [s for s in segments_data if s['episode_id'] == episode_id]\n",
    "        episode_insights = [i for i in insights_data if i['episode_id'] == episode_id]\n",
    "        \n",
    "        # Check existing embeddings in ChromaDB\n",
    "        existing_segment_ids = []\n",
    "        existing_insight_ids = []\n",
    "        \n",
    "        try:\n",
    "            # Query for existing segments\n",
    "            segment_results = segments_collection.get(\n",
    "                where={\"episode_id\": episode_id}\n",
    "            )\n",
    "            existing_segment_ids = segment_results['ids'] if segment_results else []\n",
    "            \n",
    "            # Query for existing insights\n",
    "            insight_results = insights_collection.get(\n",
    "                where={\"episode_id\": episode_id}\n",
    "            )\n",
    "            existing_insight_ids = insight_results['ids'] if insight_results else []\n",
    "        except:\n",
    "            # Collections might be empty\n",
    "            pass\n",
    "        \n",
    "        # Filter out already embedded items\n",
    "        segments_to_embed = [s for s in episode_segments if s['id'] not in existing_segment_ids]\n",
    "        insights_to_embed = [i for i in episode_insights if i['id'] not in existing_insight_ids]\n",
    "        \n",
    "        total_needed = len(segments_to_embed) + len(insights_to_embed)\n",
    "        \n",
    "        if total_needed > 0:\n",
    "            print(f\"Need to generate embeddings for:\")\n",
    "            if segments_to_embed:\n",
    "                print(f\"   - {len(segments_to_embed)} new segments\")\n",
    "            if insights_to_embed:\n",
    "                print(f\"   - {len(insights_to_embed)} new insights\")\n",
    "            \n",
    "            # Add segments to ChromaDB\n",
    "            if segments_to_embed:\n",
    "                print(\"\\nAdding segments to ChromaDB...\")\n",
    "                \n",
    "                # Prepare data for ChromaDB\n",
    "                segment_ids = [s['id'] for s in segments_to_embed]\n",
    "                segment_texts = [s['display_text'] for s in segments_to_embed]\n",
    "                segment_metadatas = [{\n",
    "                    'episode_id': s['episode_id'],\n",
    "                    'start_time': s['start_time'],\n",
    "                    'end_time': s['end_time'],\n",
    "                    'speaker': s['speaker'],\n",
    "                    'duration': s['duration']\n",
    "                } for s in segments_to_embed]\n",
    "                \n",
    "                # Add to ChromaDB in batches\n",
    "                batch_size = config.get('semantic_search', {}).get('batch_size', 20)\n",
    "                \n",
    "                for i in range(0, len(segments_to_embed), batch_size):\n",
    "                    batch_end = min(i + batch_size, len(segments_to_embed))\n",
    "                    print(f\"   Processing batch {i//batch_size + 1}/{(len(segments_to_embed)-1)//batch_size + 1}...\")\n",
    "                    \n",
    "                    segments_collection.add(\n",
    "                        documents=segment_texts[i:batch_end],\n",
    "                        ids=segment_ids[i:batch_end],\n",
    "                        metadatas=segment_metadatas[i:batch_end]\n",
    "                    )\n",
    "                \n",
    "                print(f\"Success: Added {len(segments_to_embed)} segments to ChromaDB\")\n",
    "            \n",
    "            # Add insights to ChromaDB\n",
    "            if insights_to_embed:\n",
    "                print(\"\\nAdding insights to ChromaDB...\")\n",
    "                \n",
    "                # Prepare data for ChromaDB\n",
    "                insight_ids = [i['id'] for i in insights_to_embed]\n",
    "                insight_texts = [i['content'] for i in insights_to_embed]\n",
    "                insight_metadatas = [{\n",
    "                    'episode_id': i['episode_id'],\n",
    "                    'category': i['category'],\n",
    "                    'confidence_score': i['confidence_score'],\n",
    "                    'segment_start': i['segment_start'],\n",
    "                    'segment_end': i['segment_end']\n",
    "                } for i in insights_to_embed]\n",
    "                \n",
    "                # Add all insights at once (usually fewer than segments)\n",
    "                insights_collection.add(\n",
    "                    documents=insight_texts,\n",
    "                    ids=insight_ids,\n",
    "                    metadatas=insight_metadatas\n",
    "                )\n",
    "                \n",
    "                print(f\"Success: Added {len(insights_to_embed)} insights to ChromaDB\")\n",
    "            \n",
    "            # Display summary\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style='background: #e8f5e9; padding: 15px; border-radius: 5px; margin-top: 10px;'>\n",
    "                <strong>ChromaDB Embeddings Update Complete!</strong><br>\n",
    "                <ul style='margin: 5px 0;'>\n",
    "                    <li>New segments added: {len(segments_to_embed)}</li>\n",
    "                    <li>New insights added: {len(insights_to_embed)}</li>\n",
    "                    <li>Total segments in DB: {segments_collection.count()}</li>\n",
    "                    <li>Total insights in DB: {insights_collection.count()}</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "            \n",
    "        else:\n",
    "            print(\"Success: All items already have embeddings in ChromaDB\")\n",
    "            print(f\"   Existing segments: {len(existing_segment_ids)}\")\n",
    "            print(f\"   Existing insights: {len(existing_insight_ids)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: ChromaDB operation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"Error: Missing required data (episode_id or ChromaDB collections not initialized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Pipeline Complete!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); \n",
       "                gap: 15px; margin: 20px 0;'>\n",
       "    \n",
       "        <div style='background: #3498db; color: white; padding: 20px; \n",
       "                    border-radius: 10px; text-align: center;'>\n",
       "            <div style='font-size: 24px; font-weight: bold;'>The Build - LangChain Open Deep Research</div>\n",
       "            <div style='font-size: 14px; margin-top: 5px;'>Episode</div>\n",
       "        </div>\n",
       "        \n",
       "        <div style='background: #2ecc71; color: white; padding: 20px; \n",
       "                    border-radius: 10px; text-align: center;'>\n",
       "            <div style='font-size: 24px; font-weight: bold;'>1608 seconds</div>\n",
       "            <div style='font-size: 14px; margin-top: 5px;'>Duration</div>\n",
       "        </div>\n",
       "        \n",
       "        <div style='background: #f39c12; color: white; padding: 20px; \n",
       "                    border-radius: 10px; text-align: center;'>\n",
       "            <div style='font-size: 24px; font-weight: bold;'>92</div>\n",
       "            <div style='font-size: 14px; margin-top: 5px;'>Segments</div>\n",
       "        </div>\n",
       "        \n",
       "        <div style='background: #e74c3c; color: white; padding: 20px; \n",
       "                    border-radius: 10px; text-align: center;'>\n",
       "            <div style='font-size: 24px; font-weight: bold;'>0</div>\n",
       "            <div style='font-size: 14px; margin-top: 5px;'>Insights</div>\n",
       "        </div>\n",
       "        \n",
       "        <div style='background: #9b59b6; color: white; padding: 20px; \n",
       "                    border-radius: 10px; text-align: center;'>\n",
       "            <div style='font-size: 24px; font-weight: bold;'>Processed</div>\n",
       "            <div style='font-size: 14px; margin-top: 5px;'>Status</div>\n",
       "        </div>\n",
       "        \n",
       "        <div style='background: #1abc9c; color: white; padding: 20px; \n",
       "                    border-radius: 10px; text-align: center;'>\n",
       "            <div style='font-size: 24px; font-weight: bold;'>92</div>\n",
       "            <div style='font-size: 14px; margin-top: 5px;'>ChromaDB Segments</div>\n",
       "        </div>\n",
       "        \n",
       "        <div style='background: #34495e; color: white; padding: 20px; \n",
       "                    border-radius: 10px; text-align: center;'>\n",
       "            <div style='font-size: 24px; font-weight: bold;'>0</div>\n",
       "            <div style='font-size: 14px; margin-top: 5px;'>ChromaDB Insights</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Data Storage\n",
       "\n",
       "Your data has been saved to:\n",
       "\n",
       "#### JSON Files (in `local_data` directory):\n",
       "- `episodes.json` - Episode metadata\n",
       "- `segments.json` - Transcription segments\n",
       "- `insights.json` - Extracted insights\n",
       "- `products.json` - Product mentions\n",
       "- `links.json` - Extracted links\n",
       "\n",
       "#### ChromaDB Vector Database (in `local_data/chromadb` directory):\n",
       "- **Segments Collection**: 92 embedded transcript segments\n",
       "- **Insights Collection**: 0 embedded insights\n",
       "- Persistent storage with automatic embedding generation\n",
       "- Supports semantic search with metadata filtering\n",
       "\n",
       "You can now:\n",
       "- Analyze the JSON data using pandas or other tools\n",
       "- Perform semantic searches using ChromaDB\n",
       "- Add more episodes and they'll be automatically indexed\n",
       "- Query across multiple episodes using metadata filters\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if 'episode_id' in locals() and episode_id:\n",
    "    # Mark as processed\n",
    "    with open(json_files['episodes'], 'r') as f:\n",
    "        episodes_data = json.load(f)\n",
    "    \n",
    "    for episode in episodes_data:\n",
    "        if episode['id'] == episode_id:\n",
    "            episode['is_processed'] = True\n",
    "            break\n",
    "    \n",
    "    with open(json_files['episodes'], 'w') as f:\n",
    "        json.dump(episodes_data, f, indent=2)\n",
    "    \n",
    "    # Gather statistics\n",
    "    stats = {\n",
    "        \"Episode\": episode_data['title'] if 'episode_data' in locals() else 'Unknown',\n",
    "        \"Duration\": f\"{episode_data['duration']} seconds\" if 'episode_data' in locals() else 'Unknown',\n",
    "        \"Segments\": len(segments) if 'segments' in locals() else 0,\n",
    "        \"Insights\": len(insights) if 'insights' in locals() else 0,\n",
    "        \"Status\": \"Processed\"\n",
    "    }\n",
    "    \n",
    "    # Add ChromaDB stats\n",
    "    if segments_collection and insights_collection:\n",
    "        stats[\"ChromaDB Segments\"] = segments_collection.count()\n",
    "        stats[\"ChromaDB Insights\"] = insights_collection.count()\n",
    "    \n",
    "    # Display summary\n",
    "    display(Markdown(f\"## {config.get('messages', {}).get('pipeline_complete', 'Pipeline Complete')}\"))\n",
    "    \n",
    "    stats_html = \"\"\"\n",
    "    <div style='display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); \n",
    "                gap: 15px; margin: 20px 0;'>\n",
    "    \"\"\"\n",
    "    \n",
    "    colors = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c', '#9b59b6', '#1abc9c', '#34495e']\n",
    "    \n",
    "    for i, (stat, value) in enumerate(stats.items()):\n",
    "        color = colors[i % len(colors)]\n",
    "        stats_html += f\"\"\"\n",
    "        <div style='background: {color}; color: white; padding: 20px; \n",
    "                    border-radius: 10px; text-align: center;'>\n",
    "            <div style='font-size: 24px; font-weight: bold;'>{value}</div>\n",
    "            <div style='font-size: 14px; margin-top: 5px;'>{stat}</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    stats_html += \"</div>\"\n",
    "    display(HTML(stats_html))\n",
    "    \n",
    "    display(Markdown(f\"\"\"\n",
    "### Data Storage\n",
    "\n",
    "Your data has been saved to:\n",
    "\n",
    "#### JSON Files (in `{config.get('data_directory', './')}` directory):\n",
    "- `{config.get('data_files', {}).get('episodes', 'episodes.json')}` - Episode metadata\n",
    "- `{config.get('data_files', {}).get('segments', 'segments.json')}` - Transcription segments\n",
    "- `{config.get('data_files', {}).get('insights', 'insights.json')}` - Extracted insights\n",
    "- `{config.get('data_files', {}).get('products', 'products.json')}` - Product mentions\n",
    "- `{config.get('data_files', {}).get('links', 'links.json')}` - Extracted links\n",
    "\n",
    "#### ChromaDB Vector Database (in `{config.get('data_directory', './')}/chromadb` directory):\n",
    "- **Segments Collection**: {segments_collection.count() if segments_collection else 0} embedded transcript segments\n",
    "- **Insights Collection**: {insights_collection.count() if insights_collection else 0} embedded insights\n",
    "- Persistent storage with automatic embedding generation\n",
    "- Supports semantic search with metadata filtering\n",
    "\n",
    "You can now:\n",
    "- Analyze the JSON data using pandas or other tools\n",
    "- Perform semantic searches using ChromaDB\n",
    "- Add more episodes and they'll be automatically indexed\n",
    "- Query across multiple episodes using metadata filters\n",
    "    \"\"\"))\n",
    "else:\n",
    "    print(\"Error: No episode was processed. Please run the notebook cells in order from the beginning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromaDB Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB loaded successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7682130a506344648423a8ea1550c48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Refresh Collections', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a88b5c41644b77959506bae3dcf066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1362e1f310447b3a66acb752e1ea940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314602ad63dc4f328d0b87d638dfa3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85508a04827f4a00be393953632826bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 collections\n",
      "Refreshing with 2 collections: ['insights', 'segments']\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "# Load configuration settings from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the path to the ChromaDB created by build_vault_demo.ipynb\n",
    "# The build_vault_demo.ipynb creates the database at ./local_data/chromadb\n",
    "CHROMA_DB_PATH = os.path.join(os.getcwd(), 'local_data', 'chromadb')\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.exists(CHROMA_DB_PATH):\n",
    "    print(f\"ChromaDB path not found at: {CHROMA_DB_PATH}\")\n",
    "    print(\"Please run build_vault_demo.ipynb first to create the database.\")\n",
    "else:\n",
    "    print(f\"ChromaDB loaded successfully\")\n",
    "\n",
    "# Set up chromadb client\n",
    "client = chromadb.PersistentClient(\n",
    "    path=CHROMA_DB_PATH,\n",
    "    settings=Settings(),\n",
    "    tenant=DEFAULT_TENANT,\n",
    "    database=DEFAULT_DATABASE,\n",
    ")\n",
    "\n",
    "# Function to list collections\n",
    "def list_collections():\n",
    "    collections = client.list_collections()\n",
    "    print(f\"Found {len(collections)} collections\")  # Debug print\n",
    "    return [collection.name for collection in collections]\n",
    "\n",
    "# Function to format embedding preview\n",
    "def format_embedding_preview(embedding, preview_length=10):\n",
    "    \"\"\"Format embedding vector for display\"\"\"\n",
    "    if embedding is None or len(embedding) == 0:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    # Convert to numpy array if needed\n",
    "    if isinstance(embedding, list):\n",
    "        embedding = np.array(embedding)\n",
    "    \n",
    "    # Get first few values\n",
    "    preview = embedding[:preview_length]\n",
    "    preview_str = \", \".join([f\"{x:.4f}\" for x in preview])\n",
    "    \n",
    "    # Add statistics\n",
    "    stats = f\"[{preview_str}, ...] (dim: {len(embedding)}, mean: {np.mean(embedding):.4f}, std: {np.std(embedding):.4f})\"\n",
    "    return stats\n",
    "\n",
    "# Function to display collection details\n",
    "def show_details(collection_name):\n",
    "    try:\n",
    "        collection = client.get_collection(collection_name)\n",
    "        details_output.clear_output()\n",
    "        with details_output:\n",
    "            print(f\"Collection Name: {collection_name}\")\n",
    "            print(f\"Document Count: {collection.count()}\")\n",
    "            if collection.metadata:\n",
    "                for key, value in collection.metadata.items():\n",
    "                    print(f\"{key}: {value}\")\n",
    "            else:\n",
    "                print(\"No metadata available.\")\n",
    "            \n",
    "            # Display details of the documents in the collection\n",
    "            # Include embeddings in the query\n",
    "            raw_data = collection.get(limit=5, include=['metadatas', 'documents', 'embeddings'])\n",
    "            print(\"\\nSample Documents:\")  # Better formatting\n",
    "            \n",
    "            # Extract and display relevant data\n",
    "            ids = raw_data.get('ids', [])\n",
    "            metadatas = raw_data.get('metadatas', [])\n",
    "            documents = raw_data.get('documents', [])\n",
    "            embeddings = raw_data.get('embeddings', [])\n",
    "\n",
    "            if not ids or not metadatas:\n",
    "                print(\"No documents available or missing data.\")\n",
    "                return\n",
    "\n",
    "            # Create table with clickable IDs and embedding preview\n",
    "            table_html = \"<table style='border-collapse: collapse; width: 100%;'>\"\n",
    "            table_html += \"<tr style='background-color: #f2f2f2;'>\"\n",
    "            table_html += \"<th style='border: 1px solid #ddd; padding: 8px;'>ID</th>\"\n",
    "            table_html += \"<th style='border: 1px solid #ddd; padding: 8px;'>Metadata</th>\"\n",
    "            table_html += \"<th style='border: 1px solid #ddd; padding: 8px;'>Document Preview</th>\"\n",
    "            table_html += \"<th style='border: 1px solid #ddd; padding: 8px;'>Embedding Preview</th>\"\n",
    "            table_html += \"</tr>\"\n",
    "            \n",
    "            for i, (doc_id, metadata) in enumerate(zip(ids, metadatas)):\n",
    "                doc_preview = documents[i][:100] + \"...\" if documents and i < len(documents) else \"N/A\"\n",
    "                \n",
    "                # Fixed: Handle embeddings properly regardless of type\n",
    "                embedding_preview = \"N/A\"\n",
    "                if embeddings is not None:\n",
    "                    try:\n",
    "                        if isinstance(embeddings, (list, tuple)) and len(embeddings) > i:\n",
    "                            embedding_preview = format_embedding_preview(embeddings[i])\n",
    "                        elif isinstance(embeddings, np.ndarray) and embeddings.shape[0] > i:\n",
    "                            embedding_preview = format_embedding_preview(embeddings[i])\n",
    "                    except:\n",
    "                        embedding_preview = \"N/A\"\n",
    "                \n",
    "                table_html += f\"<tr>\"\n",
    "                table_html += f\"<td style='border: 1px solid #ddd; padding: 8px;'><a href='#' onclick='IPython.notebook.kernel.execute(\\\"show_document_details(\\\\\\\"{collection_name}\\\\\\\", \\\\\\\"{doc_id}\\\\\\\")\\\")'>{doc_id[:8]}...</a></td>\"\n",
    "                table_html += f\"<td style='border: 1px solid #ddd; padding: 8px;'>{metadata}</td>\"\n",
    "                table_html += f\"<td style='border: 1px solid #ddd; padding: 8px;'>{doc_preview}</td>\"\n",
    "                table_html += f\"<td style='border: 1px solid #ddd; padding: 8px; font-family: monospace; font-size: 11px;'>{embedding_preview}</td>\"\n",
    "                table_html += \"</tr>\"\n",
    "            table_html += \"</table>\"\n",
    "            \n",
    "            display(HTML(table_html))\n",
    "    except Exception as e:\n",
    "        details_output.clear_output()\n",
    "        with details_output:\n",
    "            print(f\"Error while fetching details for collection '{collection_name}': {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Function to display individual document details\n",
    "def show_document_details(collection_name, doc_id):\n",
    "    try:\n",
    "        collection = client.get_collection(collection_name)\n",
    "        document_details_output.clear_output()\n",
    "        with document_details_output:\n",
    "            print(f\"Collection: {collection_name}, Document ID: {doc_id}\")\n",
    "            \n",
    "            # Retrieve document details including embeddings\n",
    "            raw_data = collection.get(ids=[doc_id], include=['metadatas', 'documents', 'embeddings'])\n",
    "            if not raw_data or not raw_data.get('metadatas'):\n",
    "                print(f\"No details available for document ID: {doc_id}\")\n",
    "                return\n",
    "\n",
    "            # Assuming getting first (and only one) document metadata and embeddings\n",
    "            metadata = raw_data['metadatas'][0]\n",
    "            document = raw_data['documents'][0] if raw_data.get('documents') else \"N/A\"\n",
    "            \n",
    "            # Handle embeddings safely\n",
    "            embedding = None\n",
    "            embeddings = raw_data.get('embeddings')\n",
    "            if embeddings is not None:\n",
    "                try:\n",
    "                    if isinstance(embeddings, (list, tuple)) and len(embeddings) > 0:\n",
    "                        embedding = embeddings[0]\n",
    "                    elif isinstance(embeddings, np.ndarray) and embeddings.shape[0] > 0:\n",
    "                        embedding = embeddings[0]\n",
    "                except:\n",
    "                    embedding = None\n",
    "            \n",
    "            print(\"\\nMetadata:\")\n",
    "            for key, value in metadata.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "            \n",
    "            print(\"\\nDocument Content:\")\n",
    "            print(f\"  {document}\")\n",
    "            \n",
    "            if embedding is not None:\n",
    "                print(\"\\nEmbedding Information:\")\n",
    "                print(f\"  Dimension: {len(embedding)}\")\n",
    "                print(f\"  Mean: {np.mean(embedding):.6f}\")\n",
    "                print(f\"  Std Dev: {np.std(embedding):.6f}\")\n",
    "                print(f\"  Min: {np.min(embedding):.6f}\")\n",
    "                print(f\"  Max: {np.max(embedding):.6f}\")\n",
    "                print(f\"  First 20 values: {embedding[:20]}\")\n",
    "                \n",
    "                # Optional: Create a simple visualization of the embedding\n",
    "                try:\n",
    "                    import matplotlib.pyplot as plt\n",
    "                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "                    \n",
    "                    # Histogram of embedding values\n",
    "                    ax1.hist(embedding, bins=50, alpha=0.7, color='blue')\n",
    "                    ax1.set_xlabel('Embedding Value')\n",
    "                    ax1.set_ylabel('Frequency')\n",
    "                    ax1.set_title('Distribution of Embedding Values')\n",
    "                    \n",
    "                    # Plot first 100 dimensions\n",
    "                    ax2.plot(embedding[:100], alpha=0.7, color='green')\n",
    "                    ax2.set_xlabel('Dimension')\n",
    "                    ax2.set_ylabel('Value')\n",
    "                    ax2.set_title('First 100 Embedding Dimensions')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not create visualization: {e}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        document_details_output.clear_output()\n",
    "        with document_details_output:\n",
    "            print(f\"Error while fetching details for document ID '{doc_id}': {str(e)}\")\n",
    "\n",
    "\n",
    "# Function to delete collection\n",
    "def delete_collection(collection_name):\n",
    "    try:\n",
    "        client.delete_collection(collection_name)\n",
    "        refresh_collections()\n",
    "    except Exception as e:\n",
    "        error_output.clear_output()\n",
    "        with error_output:\n",
    "            print(f\"Error while deleting collection '{collection_name}': {str(e)}\")\n",
    "\n",
    "# Function to refresh the list of collections\n",
    "def refresh_collections():\n",
    "    try:\n",
    "        collection_names = list_collections()\n",
    "        print(f\"Refreshing with {len(collection_names)} collections: {collection_names}\")  # Debug print\n",
    "        \n",
    "        if not collection_names:\n",
    "            collection_buttons.children = [widgets.Label(value=\"No collections found in the database.\")]\n",
    "        else:\n",
    "            collection_buttons.children = [\n",
    "                widgets.HBox([\n",
    "                    widgets.Label(value=collection_name, layout=widgets.Layout(width='200px')),\n",
    "                    widgets.Button(description=\"Delete\", button_style='danger', layout=widgets.Layout(width='100px')),\n",
    "                    widgets.Button(description=\"Details\", button_style='info', layout=widgets.Layout(width='100px'))\n",
    "                ])\n",
    "                for collection_name in collection_names\n",
    "            ]\n",
    "            \n",
    "            for box in collection_buttons.children:\n",
    "                name_label, delete_button, details_button = box.children\n",
    "                \n",
    "                # Use default arguments in lambda to capture the current collection name\n",
    "                delete_button.on_click(lambda b, name=name_label.value: delete_collection(name))\n",
    "                details_button.on_click(lambda b, name=name_label.value: show_details(name))\n",
    "    except Exception as e:\n",
    "        print(f\"Error refreshing collections: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Set up widgets\n",
    "details_output = widgets.Output()\n",
    "document_details_output = widgets.Output()\n",
    "error_output = widgets.Output()\n",
    "collection_buttons = widgets.VBox()\n",
    "refresh_button = widgets.Button(description=\"Refresh Collections\", button_style='primary')\n",
    "refresh_button.on_click(lambda b: refresh_collections())\n",
    "\n",
    "# Display widgets in the Jupyter notebook\n",
    "display(refresh_button, collection_buttons, details_output, document_details_output, error_output)\n",
    "\n",
    "# Initialize the list of collections\n",
    "refresh_collections()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}