{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Podcast GraphRAG with Neo4j\n",
    "\n",
    "This notebook demonstrates a Graph-based Question Answering system using Neo4j and LangChain for YouTube podcast data. It creates a knowledge graph from podcast transcripts, insights, and product mentions to enable complex queries about the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-groq neo4j langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API Keys\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Neo4j Connection\n",
    "NEO4J_URI = os.getenv('NEO4J_URI') \n",
    "NEO4J_USER = os.getenv('NEO4J_USER')\n",
    "NEO4J_PW = os.getenv('NEO4J_PW')\n",
    "\n",
    "# Local LLM (Ollama)\n",
    "LLM_BASE_URL = os.getenv('LLM_BASE_URL')\n",
    "LLM_MODEL = os.getenv('LLM_MODEL')\n",
    "LLM_TEMPERATURE = float(os.getenv('LLM_TEMPERATURE', '0.0'))\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'local_data')\n",
    "\n",
    "print(\"Environment loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "from neo4j import GraphDatabase\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 episodes\n",
      "Loaded 19 segments\n",
      "Loaded 0 insights\n",
      "Loaded 30 products\n",
      "Loaded 0 links\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline configuration\n",
    "config_path = os.path.join(os.getcwd(), 'pipeline_config.json')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Define data file paths\n",
    "json_files = {\n",
    "    'episodes': os.path.join(DATA_DIR, config['data_files']['episodes']),\n",
    "    'segments': os.path.join(DATA_DIR, config['data_files']['segments']),\n",
    "    'insights': os.path.join(DATA_DIR, config['data_files']['insights']),\n",
    "    'products': os.path.join(DATA_DIR, config['data_files']['products']),\n",
    "    'links': os.path.join(DATA_DIR, config['data_files']['links'])\n",
    "}\n",
    "\n",
    "# Load all data\n",
    "data = {}\n",
    "for key, path in json_files.items():\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            data[key] = json.load(f)\n",
    "            print(f\"Loaded {len(data[key])} {key}\")\n",
    "    else:\n",
    "        data[key] = []\n",
    "        print(f\"Warning: {key} file not found at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Neo4j driver for data population\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PW))\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"RETURN 1\")\n",
    "        print(\"Neo4j connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Neo4j connection failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Existing Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database cleared\n"
     ]
    }
   ],
   "source": [
    "# Clear existing data - uncomment to reset database\n",
    "with driver.session() as session:\n",
    "     session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "     print(\"Database cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: (e:Episode)\n",
      "Created: (s:Segment)\n",
      "Created: (sp:Speaker)\n",
      "Created: (i:Insight)\n",
      "Created: (p:Product)\n",
      "Created: (t:Topic)\n"
     ]
    }
   ],
   "source": [
    "# Create constraints and indexes for better performance\n",
    "with driver.session() as session:\n",
    "    # Create constraints\n",
    "    constraints = [\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (e:Episode) REQUIRE e.id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (s:Segment) REQUIRE s.id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (sp:Speaker) REQUIRE sp.name IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (i:Insight) REQUIRE i.id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (p:Product) REQUIRE p.name IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (t:Topic) REQUIRE t.name IS UNIQUE\"\n",
    "    ]\n",
    "    \n",
    "    for constraint in constraints:\n",
    "        try:\n",
    "            session.run(constraint)\n",
    "            print(f\"Created: {constraint.split('FOR')[1].split('REQUIRE')[0].strip()}\")\n",
    "        except Exception as e:\n",
    "            if \"already exists\" not in str(e):\n",
    "                print(f\"Error creating constraint: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Graph Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_episodes(session, episodes):\n",
    "    \"\"\"Create Episode nodes\"\"\"\n",
    "    query = \"\"\"\n",
    "    UNWIND $episodes AS episode\n",
    "    MERGE (e:Episode {id: episode.id})\n",
    "    SET e.title = episode.title,\n",
    "        e.youtube_video_id = episode.youtube_video_id,\n",
    "        e.youtube_url = episode.youtube_url,\n",
    "        e.duration = episode.duration,\n",
    "        e.published_at = episode.published_at,\n",
    "        e.summary = episode.summary\n",
    "    \"\"\"\n",
    "    session.run(query, episodes=episodes)\n",
    "    print(f\"Created {len(episodes)} Episode nodes\")\n",
    "\n",
    "def populate_segments_and_speakers(session, segments):\n",
    "    \"\"\"Create Segment nodes and Speaker nodes, with relationships\"\"\"\n",
    "    # Create segments\n",
    "    segment_query = \"\"\"\n",
    "    UNWIND $segments AS segment\n",
    "    MERGE (s:Segment {id: segment.id})\n",
    "    SET s.start_time = segment.start_time,\n",
    "        s.end_time = segment.end_time,\n",
    "        s.text = segment.display_text,\n",
    "        s.confidence = segment.confidence,\n",
    "        s.duration = segment.duration,\n",
    "        s.episode_id = segment.episode_id\n",
    "    WITH s, segment\n",
    "    MATCH (e:Episode {id: segment.episode_id})\n",
    "    MERGE (e)-[:HAS_SEGMENT]->(s)\n",
    "    \"\"\"\n",
    "    session.run(segment_query, segments=segments)\n",
    "    print(f\"Created {len(segments)} Segment nodes\")\n",
    "    \n",
    "    # Create speakers and relationships\n",
    "    speaker_query = \"\"\"\n",
    "    UNWIND $segments AS segment\n",
    "    MERGE (sp:Speaker {name: segment.speaker})\n",
    "    WITH sp, segment\n",
    "    MATCH (s:Segment {id: segment.id})\n",
    "    MERGE (sp)-[:SPEAKS_IN]->(s)\n",
    "    \"\"\"\n",
    "    session.run(speaker_query, segments=segments)\n",
    "    \n",
    "    # Create FOLLOWED_BY relationships for temporal flow\n",
    "    temporal_query = \"\"\"\n",
    "    MATCH (s1:Segment), (s2:Segment)\n",
    "    WHERE s1.episode_id = s2.episode_id \n",
    "      AND s1.end_time = s2.start_time\n",
    "    MERGE (s1)-[:FOLLOWED_BY]->(s2)\n",
    "    \"\"\"\n",
    "    session.run(temporal_query)\n",
    "    print(\"Created temporal relationships between segments\")\n",
    "\n",
    "def populate_products(session, products):\n",
    "    \"\"\"Create Product nodes\"\"\"\n",
    "    query = \"\"\"\n",
    "    UNWIND $products AS product\n",
    "    MERGE (p:Product {name: product.name})\n",
    "    SET p.id = product.id,\n",
    "        p.mention_count = product.mention_count\n",
    "    \"\"\"\n",
    "    session.run(query, products=products)\n",
    "    print(f\"Created {len(products)} Product nodes\")\n",
    "\n",
    "def populate_insights(session, insights):\n",
    "    \"\"\"Create Insight nodes and relationships\"\"\"\n",
    "    query = \"\"\"\n",
    "    UNWIND $insights AS insight\n",
    "    MERGE (i:Insight {id: insight.id})\n",
    "    SET i.content = insight.content,\n",
    "        i.category = insight.category,\n",
    "        i.confidence_score = insight.confidence_score,\n",
    "        i.segment_start = insight.segment_start,\n",
    "        i.segment_end = insight.segment_end\n",
    "    WITH i, insight\n",
    "    MATCH (e:Episode {id: insight.episode_id})\n",
    "    MERGE (e)-[:CONTAINS_INSIGHT]->(i)\n",
    "    \"\"\"\n",
    "    session.run(query, insights=insights)\n",
    "    print(f\"Created {len(insights)} Insight nodes\")\n",
    "    \n",
    "    # Create Topic nodes from insight categories\n",
    "    topic_query = \"\"\"\n",
    "    MATCH (i:Insight)\n",
    "    WITH DISTINCT i.category AS category\n",
    "    MERGE (t:Topic {name: category})\n",
    "    SET t.category = 'insight_category'\n",
    "    \"\"\"\n",
    "    session.run(topic_query)\n",
    "    \n",
    "    # Link insights to topics\n",
    "    link_query = \"\"\"\n",
    "    MATCH (i:Insight)\n",
    "    MATCH (t:Topic {name: i.category})\n",
    "    MERGE (i)-[:RELATED_TO]->(t)\n",
    "    \"\"\"\n",
    "    session.run(link_query)\n",
    "    print(\"Created Topic nodes and relationships\")\n",
    "\n",
    "def link_products_to_content(session, segments, products, insights):\n",
    "    \"\"\"Create relationships between products and content\"\"\"\n",
    "    # Get product names for matching\n",
    "    product_names = [p['name'] for p in products]\n",
    "    \n",
    "    # Link segments to products they mention\n",
    "    for segment in segments[:100]:  # Limit for performance\n",
    "        for product_name in product_names:\n",
    "            if product_name.lower() in segment.get('display_text', '').lower():\n",
    "                query = \"\"\"\n",
    "                MATCH (s:Segment {id: $segment_id})\n",
    "                MATCH (p:Product {name: $product_name})\n",
    "                MERGE (s)-[:MENTIONS]->(p)\n",
    "                \"\"\"\n",
    "                session.run(query, segment_id=segment['id'], product_name=product_name)\n",
    "    \n",
    "    # Link insights to products they discuss\n",
    "    for insight in insights:\n",
    "        for product_name in product_names:\n",
    "            if product_name.lower() in insight.get('content', '').lower():\n",
    "                query = \"\"\"\n",
    "                MATCH (i:Insight {id: $insight_id})\n",
    "                MATCH (p:Product {name: $product_name})\n",
    "                MERGE (i)-[:ABOUT]->(p)\n",
    "                \"\"\"\n",
    "                session.run(query, insight_id=insight['id'], product_name=product_name)\n",
    "    \n",
    "    print(\"Created product relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1 Episode nodes\n",
      "Created 19 Segment nodes\n",
      "Created temporal relationships between segments\n",
      "Created 30 Product nodes\n",
      "\n",
      "Graph database population complete!\n"
     ]
    }
   ],
   "source": [
    "# Populate the graph database\n",
    "with driver.session() as session:\n",
    "    if data['episodes']:\n",
    "        populate_episodes(session, data['episodes'])\n",
    "    \n",
    "    if data['segments']:\n",
    "        populate_segments_and_speakers(session, data['segments'])\n",
    "    \n",
    "    if data['products']:\n",
    "        populate_products(session, data['products'])\n",
    "    \n",
    "    if data['insights']:\n",
    "        populate_insights(session, data['insights'])\n",
    "    \n",
    "    if data['segments'] and data['products'] and data['insights']:\n",
    "        link_products_to_content(session, data['segments'], data['products'], data['insights'])\n",
    "\n",
    "print(\"\\nGraph database population complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Graph Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Episode {id: STRING, title: STRING, youtube_video_id: STRING, youtube_url: STRING, duration: INTEGER, published_at: STRING, summary: STRING}\n",
      "Segment {id: STRING, duration: FLOAT, start_time: FLOAT, end_time: FLOAT, text: STRING, confidence: FLOAT, episode_id: STRING}\n",
      "Speaker {name: STRING}\n",
      "Product {id: STRING, name: STRING, mention_count: INTEGER}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Episode)-[:HAS_SEGMENT]->(:Segment)\n",
      "(:Segment)-[:FOLLOWED_BY]->(:Segment)\n",
      "(:Speaker)-[:SPEAKS_IN]->(:Segment)\n"
     ]
    }
   ],
   "source": [
    "graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USER, password=NEO4J_PW)\n",
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Enhanced Graph Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "- **Episode**\n",
      "  - `id`: STRING Available options: ['890caf28-4dfd-461b-861a-5fe95034183a']\n",
      "  - `title`: STRING Available options: ['The Build - Agents as MCP Tools']\n",
      "  - `youtube_video_id`: STRING Available options: ['9I_WxAMQ9_0']\n",
      "  - `youtube_url`: STRING Available options: ['https://www.youtube.com/watch?v=9I_WxAMQ9_0&t=6s']\n",
      "  - `duration`: INTEGER Min: 733, Max: 733\n",
      "  - `published_at`: STRING Available options: ['2025-07-24T10:27:52.186400']\n",
      "  - `summary`: STRING Available options: ['']\n",
      "- **Segment**\n",
      "  - `id`: STRING Example: \"bf4d13ff-f34e-40c0-9c27-d3e9e54d3bc4\"\n",
      "  - `duration`: FLOAT Min: 1.04, Max: 110.87\n",
      "  - `start_time`: FLOAT Min: 0.16, Max: 712.57\n",
      "  - `end_time`: FLOAT Min: 3.04, Max: 732.57\n",
      "  - `text`: STRING Example: \"Did you just say that applications as agents?\"\n",
      "  - `confidence`: FLOAT Min: 0.93134767, Max: 0.99505615\n",
      "  - `episode_id`: STRING Available options: ['890caf28-4dfd-461b-861a-5fe95034183a']\n",
      "- **Speaker**\n",
      "  - `name`: STRING Available options: ['Speaker A', 'Speaker B']\n",
      "- **Product**\n",
      "  - `id`: STRING Example: \"94ee8809-7f23-4f89-921d-e966531bbcb5\"\n",
      "  - `name`: STRING Example: \"IO\"\n",
      "  - `mention_count`: INTEGER Min: 1, Max: 11\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Episode)-[:HAS_SEGMENT]->(:Segment)\n",
      "(:Segment)-[:FOLLOWED_BY]->(:Segment)\n",
      "(:Speaker)-[:SPEAKS_IN]->(:Segment)\n"
     ]
    }
   ],
   "source": [
    "enhanced_graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USER,\n",
    "    password=NEO4J_PW,\n",
    "    enhanced_schema=True,\n",
    ")\n",
    "print(enhanced_graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Queries for YouTube Podcast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which products were discussed most frequently in the podcast? Show top 10 with their mention counts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Product)\n",
      "RETURN p.name AS product, p.mention_count AS mentions\n",
      "ORDER BY p.mention_count DESC\n",
      "LIMIT 10\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product': 'IO', 'mentions': 11}, {'product': 'MCP', 'mentions': 6}, {'product': 'Tool Swarm', 'mentions': 4}, {'product': 'MCP Tool', 'mentions': 4}, {'product': 'Claude', 'mentions': 3}, {'product': 'LangChain', 'mentions': 3}, {'product': 'CLAUDE Desktop', 'mentions': 2}, {'product': 'Claude Desktop', 'mentions': 2}, {'product': 'Claude desktop', 'mentions': 2}, {'product': 'Flow', 'mentions': 2}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Intermediate steps: [{'query': 'MATCH (p:Product)\\nRETURN p.name AS product, p.mention_count AS mentions\\nORDER BY p.mention_count DESC\\nLIMIT 10'}, {'context': [{'product': 'IO', 'mentions': 11}, {'product': 'MCP', 'mentions': 6}, {'product': 'Tool Swarm', 'mentions': 4}, {'product': 'MCP Tool', 'mentions': 4}, {'product': 'Claude', 'mentions': 3}, {'product': 'LangChain', 'mentions': 3}, {'product': 'CLAUDE Desktop', 'mentions': 2}, {'product': 'Claude Desktop', 'mentions': 2}, {'product': 'Claude desktop', 'mentions': 2}, {'product': 'Flow', 'mentions': 2}]}]\n",
      "Final answer: The top 10 products discussed most frequently in the podcast are:\n",
      "1. IO – 11 mentions  \n",
      "2. MCP – 6 mentions  \n",
      "3. Tool Swarm – 4 mentions  \n",
      "4. MCP Tool – 4 mentions  \n",
      "5. Claude – 3 mentions  \n",
      "6. LangChain – 3 mentions  \n",
      "7. CLAUDE Desktop – 2 mentions  \n",
      "8. Claude Desktop – 2 mentions  \n",
      "9. Claude desktop – 2 mentions  \n",
      "10. Flow – 2 mentions\n"
     ]
    }
   ],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(model=\"o4-mini\"), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True, \n",
    "    return_intermediate_steps=True,\n",
    ")\n",
    "result = chain.invoke({\"query\": query})\n",
    "print(f\"Intermediate steps: {result['intermediate_steps']}\")\n",
    "print(f\"Final answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROQ MODELS LIST\n",
    "--- Production ---  \n",
    "distil-whisper-large-v3-en  \n",
    "gemma2-9b-it  \n",
    "llama-3.1-8b-instant  \n",
    "llama-3.3-70b-versatile  \n",
    "meta-llama/llama-guard-4-12b  \n",
    "whisper-large-v3  \n",
    "whisper-large-v3-turbo  \n",
    "\n",
    "--- Preview ---  \n",
    "deepseek-r1-distill-llama-70b  \n",
    "meta-llama/llama-4-maverick-17b-128e-instruct  \n",
    "meta-llama/llama-4-scout-17b-16e-instruct  \n",
    "meta-llama/llama-prompt-guard-2-22m  \n",
    "meta-llama/llama-prompt-guard-2-86m  \n",
    "mistral-saba-24b  \n",
    "moonshotai/kimi-k2-instruct  \n",
    "playai-tts \n",
    "playai-tts-arabic   \n",
    "qwen/qwen3-32b  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Product)\n",
      "RETURN p.name AS product, p.mention_count AS mentions\n",
      "ORDER BY p.mention_count DESC\n",
      "LIMIT 10\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product': 'IO', 'mentions': 11}, {'product': 'MCP', 'mentions': 6}, {'product': 'Tool Swarm', 'mentions': 4}, {'product': 'MCP Tool', 'mentions': 4}, {'product': 'Claude', 'mentions': 3}, {'product': 'LangChain', 'mentions': 3}, {'product': 'CLAUDE Desktop', 'mentions': 2}, {'product': 'Claude Desktop', 'mentions': 2}, {'product': 'Claude desktop', 'mentions': 2}, {'product': 'Flow', 'mentions': 2}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Intermediate steps: [{'query': 'MATCH (p:Product)\\nRETURN p.name AS product, p.mention_count AS mentions\\nORDER BY p.mention_count DESC\\nLIMIT 10'}, {'context': [{'product': 'IO', 'mentions': 11}, {'product': 'MCP', 'mentions': 6}, {'product': 'Tool Swarm', 'mentions': 4}, {'product': 'MCP Tool', 'mentions': 4}, {'product': 'Claude', 'mentions': 3}, {'product': 'LangChain', 'mentions': 3}, {'product': 'CLAUDE Desktop', 'mentions': 2}, {'product': 'Claude Desktop', 'mentions': 2}, {'product': 'Claude desktop', 'mentions': 2}, {'product': 'Flow', 'mentions': 2}]}]\n",
      "Final answer: The most frequently discussed products in the podcast were:\n",
      "\n",
      "1. IO - 11 mentions\n",
      "2. MCP - 6 mentions\n",
      "3. Tool Swarm - 4 mentions\n",
      "4. MCP Tool - 4 mentions\n",
      "5. Claude - 3 mentions\n",
      "6. LangChain - 3 mentions\n",
      "7. CLAUDE Desktop - 2 mentions\n",
      "8. Claude Desktop - 2 mentions\n",
      "9. Claude desktop - 2 mentions\n",
      "10. Flow - 2 mentions\n"
     ]
    }
   ],
   "source": [
    "model = \"moonshotai/kimi-k2-instruct\"\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatGroq(model=model, temperature=0, max_tokens=None, timeout=None, max_retries=2,), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True, \n",
    "    return_intermediate_steps=True,\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": query})\n",
    "print(f\"Intermediate steps: {result['intermediate_steps']}\")\n",
    "print(f\"Final answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLLAMA MODELS LIST  \n",
    "gemma3n:e4b  \n",
    "deepseek-r1:latest  \n",
    "devstral:latest  \n",
    "gemma3:12b  \n",
    "gemma3:4b  \n",
    "gemma3:latest  \n",
    "llama3.2:latest  \n",
    "llama3.1:latest  \n",
    "nomic-embed-text:latest  \n",
    "phi4-mini:latest  \n",
    "qwen2.5vl:latest  \n",
    "qwen3:14b  \n",
    "qwen3:4b  \n",
    "qwen3:1.7b  \n",
    "qwen3:0.6b  \n",
    "qwen3:latest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, let's see. The user wants to find out which products were discussed most frequently in the podcast and show the top 10 with their mention counts. \n",
      "\n",
      "First, I need to look at the schema provided. The nodes involved here are Product and Segment. The Product node has a mention_count property, but wait, the Segment node has a mention_count? Wait, no. Wait, looking back: the Product node has mention_count as a property. Wait, no. Let me check again.\n",
      "\n",
      "Wait, the schema says:\n",
      "\n",
      "Node properties:\n",
      "Episode {id, title, youtube_video_id, youtube_url, duration, published_at, summary}\n",
      "Segment {id, duration, start_time, end_time, text, confidence, episode_id}\n",
      "Speaker {name}\n",
      "Product {id, name, mention_count}\n",
      "\n",
      "Oh, right! The Product node has a mention_count property. But how does that relate to the Segments? Because the question is about products discussed in the podcast. So maybe the mention_count in the Product node is the count of how many times the product was mentioned across all segments. But that might not be the case. Wait, perhaps the mention_count is stored per product, but how is it calculated?\n",
      "\n",
      "Alternatively, maybe the Segments have text, and the Product mentions are in the text. But the schema doesn't have a direct relationship between Product and Segment. Wait, the relationships given are:\n",
      "\n",
      "- Episode has segments via HAS_SEGMENT\n",
      "- Segments are connected via FOLLOWED_BY\n",
      "- Speaker speaks in Segments via SPEAKS_IN\n",
      "\n",
      "So there's no direct relationship between Product and Segment. So how do we link products to segments?\n",
      "\n",
      "Wait, perhaps the Product's mention_count is derived from the Segments. But the schema says that Product has mention_count as a property. So maybe the mention_count is already precomputed. But the user is asking for the products discussed most frequently, which would be based on how many times they were mentioned in the segments. However, the schema's Product node has mention_count, which might be the count. But if that's the case, then the query would be straightforward: select the top 10 products ordered by mention_count descending.\n",
      "\n",
      "But wait, maybe the mention_count is not accurate, and we need to calculate it by checking how many times each product is mentioned in the segments. However, the schema doesn't have a direct relationship between Product and Segment. So perhaps the mention_count in the Product node is the correct count, and we can just order by that.\n",
      "\n",
      "But the question says \"products were discussed most frequently\", which implies that we need to count mentions in the segments. However, the schema doesn't have a direct link between Product and Segment. Therefore, maybe the mention_count in the Product node is the count of mentions. Therefore, the query would be to get all products, order by mention_count descending, limit 10.\n",
      "\n",
      "But maybe the mention_count is not the correct way. Let me think again. If the Product node's mention_count is the number of times it's mentioned in the segments, then the answer is simple. But if not, perhaps we need to find a way to count mentions. However, since there's no relationship between Product and Segment, perhaps the mention_count is stored in the Product node. \n",
      "\n",
      "Alternatively, perhaps the mention_count is a property of the Segment, but looking back, the Segment node doesn't have mention_count. The Product node has mention_count. So the answer is to get products ordered by mention_count descending, limit 10.\n",
      "\n",
      "But the user might be expecting that the mention_count is calculated by the number of times the product's name appears in the segments' text. However, without a direct relationship, that would require a full-text search, which isn't possible with the given schema. Therefore, the only way is to rely on the mention_count property in the Product node.\n",
      "\n",
      "Therefore, the Cypher query would be:\n",
      "\n",
      "MATCH (p:Product)\n",
      "RETURN p.name, p.mention_count\n",
      "ORDER BY p.mention_count DESC\n",
      "LIMIT 10\n",
      "\n",
      "But wait, the question says \"products were discussed most frequently\", which is the same as the mention_count. So this query would work. However, the user might have intended that the mention_count is not already calculated, but the schema says it is a property. So the answer is as above.\n",
      "\n",
      "But let me check again. The Product node has mention_count as a property. So the query is straightforward. So the correct Cypher statement is to select products, order by mention_count descending, limit 10.\n",
      "</think>\n",
      "\n",
      "MATCH (p:Product)\n",
      "RETURN p.name, p.mention_count\n",
      "ORDER BY p.mention_count DESC\n",
      "LIMIT 10\u001b[0m\n"
     ]
    },
    {
     "ename": "CypherSyntaxError",
     "evalue": "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '<': expected 'FOREACH', 'ALTER', 'ORDER BY', 'CALL', 'USING PERIODIC COMMIT', 'CREATE', 'LOAD CSV', 'START DATABASE', 'STOP DATABASE', 'DEALLOCATE', 'DELETE', 'DENY', 'DETACH', 'DROP', 'DRYRUN', 'FINISH', 'GRANT', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REALLOCATE', 'REMOVE', 'RENAME', 'RETURN', 'REVOKE', 'ENABLE SERVER', 'SET', 'SHOW', 'SKIP', 'TERMINATE', 'UNWIND', 'USE' or 'WITH' (line 1, column 1 (offset: 0))\n\"<think>\"\n ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCypherSyntaxError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m model = \u001b[33m\"\u001b[39m\u001b[33mqwen3:latest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m chain = GraphCypherQAChain.from_llm(\n\u001b[32m      4\u001b[39m     ChatOllama(base_url=LLM_BASE_URL, model=model), \n\u001b[32m      5\u001b[39m     graph=enhanced_graph, \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     return_intermediate_steps=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m result = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIntermediate steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mintermediate_steps\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/langchain/chains/base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/langchain_community/chains/graph_qa/cypher.py:392\u001b[39m, in \u001b[36mGraphCypherQAChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;66;03m# Retrieve and limit the number of results\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;66;03m# Generated Cypher be null if query corrector identifies invalid schema\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m generated_cypher:\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m     context = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_cypher\u001b[49m\u001b[43m)\u001b[49m[: \u001b[38;5;28mself\u001b[39m.top_k]\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    394\u001b[39m     context = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/langchain_community/graphs/neo4j_graph.py:467\u001b[39m, in \u001b[36mNeo4jGraph.query\u001b[39m\u001b[34m(self, query, params)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mneo4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Neo4jError\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     data, _, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_driver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase_\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_database\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    472\u001b[39m     json_data = [r.data() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sanitize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/driver.py:970\u001b[39m, in \u001b[36mDriver.execute_query\u001b[39m\u001b[34m(self, query_, parameters_, routing_, database_, impersonated_user_, bookmark_manager_, auth_, result_transformer_, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    967\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid routing control value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrouting_\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    968\u001b[39m     )\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m session._pipelined_begin:\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mTelemetryAPI\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDRIVER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_transformer_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/work/session.py:583\u001b[39m, in \u001b[36mSession._run_transaction\u001b[39m\u001b[34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[39m\n\u001b[32m    581\u001b[39m tx = \u001b[38;5;28mself\u001b[39m._transaction\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     result = \u001b[43mtransaction_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n\u001b[32m    585\u001b[39m     \u001b[38;5;66;03m# if cancellation callback has not been called yet:\u001b[39;00m\n\u001b[32m    586\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_work/query.py:144\u001b[39m, in \u001b[36munit_of_work.<locals>.wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/driver.py:1306\u001b[39m, in \u001b[36m_work\u001b[39m\u001b[34m(tx, query, parameters, transformer)\u001b[39m\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_work\u001b[39m(\n\u001b[32m   1301\u001b[39m     tx: ManagedTransaction,\n\u001b[32m   1302\u001b[39m     query: te.LiteralString,\n\u001b[32m   1303\u001b[39m     parameters: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, t.Any],\n\u001b[32m   1304\u001b[39m     transformer: t.Callable[[Result], t.Union[_T]],\n\u001b[32m   1305\u001b[39m ) -> _T:\n\u001b[32m-> \u001b[39m\u001b[32m1306\u001b[39m     res = \u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m transformer(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/work/transaction.py:206\u001b[39m, in \u001b[36mTransactionBase.run\u001b[39m\u001b[34m(self, query, parameters, **kwparameters)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28mself\u001b[39m._results.append(result)\n\u001b[32m    205\u001b[39m parameters = \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, **kwparameters)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tx_ready_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/work/result.py:177\u001b[39m, in \u001b[36mResult._tx_ready_run\u001b[39m\u001b[34m(self, query, parameters)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_tx_ready_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, parameters):\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# BEGIN+RUN does not carry any extra on the RUN message.\u001b[39;00m\n\u001b[32m    175\u001b[39m     \u001b[38;5;66;03m# BEGIN {extra}\u001b[39;00m\n\u001b[32m    176\u001b[39m     \u001b[38;5;66;03m# RUN \"query\" {parameters} {extra}\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/work/result.py:236\u001b[39m, in \u001b[36mResult._run\u001b[39m\u001b[34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28mself\u001b[39m._pull()\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m._connection.send_all()\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/work/result.py:430\u001b[39m, in \u001b[36mResult._attach\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/io/_common.py:184\u001b[39m, in \u001b[36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwargs):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    186\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio.iscoroutinefunction(\u001b[38;5;28mself\u001b[39m.__on_error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/io/_bolt.py:864\u001b[39m, in \u001b[36mBolt.fetch_message\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[32m    861\u001b[39m tag, fields = \u001b[38;5;28mself\u001b[39m.inbox.pop(\n\u001b[32m    862\u001b[39m     hydration_hooks=\u001b[38;5;28mself\u001b[39m.responses[\u001b[32m0\u001b[39m].hydration_hooks\n\u001b[32m    863\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m.idle_since = monotonic()\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/io/_bolt5.py:500\u001b[39m, in \u001b[36mBolt5x0._process_message\u001b[39m\u001b[34m(self, tag, fields)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28mself\u001b[39m._server_state_manager.state = \u001b[38;5;28mself\u001b[39m.bolt_states.FAILED\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pool:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.3/libexec/lib/python3.13/site-packages/neo4j/_sync/io/_common.py:254\u001b[39m, in \u001b[36mResponse.on_failure\u001b[39m\u001b[34m(self, metadata)\u001b[39m\n\u001b[32m    252\u001b[39m handler = \u001b[38;5;28mself\u001b[39m.handlers.get(\u001b[33m\"\u001b[39m\u001b[33mon_summary\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    253\u001b[39m Util.callback(handler)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._hydrate_error(metadata)\n",
      "\u001b[31mCypherSyntaxError\u001b[39m: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '<': expected 'FOREACH', 'ALTER', 'ORDER BY', 'CALL', 'USING PERIODIC COMMIT', 'CREATE', 'LOAD CSV', 'START DATABASE', 'STOP DATABASE', 'DEALLOCATE', 'DELETE', 'DENY', 'DETACH', 'DROP', 'DRYRUN', 'FINISH', 'GRANT', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REALLOCATE', 'REMOVE', 'RENAME', 'RETURN', 'REVOKE', 'ENABLE SERVER', 'SET', 'SHOW', 'SKIP', 'TERMINATE', 'UNWIND', 'USE' or 'WITH' (line 1, column 1 (offset: 0))\n\"<think>\"\n ^}"
     ]
    }
   ],
   "source": [
    "model = \"qwen3:latest\"\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOllama(base_url=LLM_BASE_URL, model=model), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True, \n",
    "    return_intermediate_steps=True,\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": query})\n",
    "print(f\"Intermediate steps: {result['intermediate_steps']}\")\n",
    "print(f\"Final answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Example Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Timeline of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_query = \"Show the timeline of different insight categories discussed in the episode, ordered by when they first appear\"\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": timeline_query})\n",
    "print(f\"\\nResult: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Speaker Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_query = \"Which speaker spoke the most in the podcast? Show the number of segments for each speaker.\"\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": speaker_query})\n",
    "print(f\"\\nResult: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Product Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_insights_query = \"Find all insights that mention MCP or agents. Show the insight content and confidence score.\"\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": product_insights_query})\n",
    "print(f\"\\nResult: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Conversation Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_query = \"Show a sample of the conversation flow - find 5 consecutive segments and show who spoke and what they said\"\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": flow_query})\n",
    "print(f\"\\nResult: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Graph Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get node counts\n",
    "with driver.session() as session:\n",
    "    node_counts = {}\n",
    "    for label in ['Episode', 'Segment', 'Speaker', 'Insight', 'Product', 'Topic']:\n",
    "        result = session.run(f\"MATCH (n:{label}) RETURN count(n) as count\")\n",
    "        node_counts[label] = result.single()['count']\n",
    "    \n",
    "    # Get relationship counts\n",
    "    rel_counts = {}\n",
    "    relationships = [\n",
    "        'HAS_SEGMENT', 'SPEAKS_IN', 'MENTIONS', 'CONTAINS_INSIGHT', \n",
    "        'ABOUT', 'RELATED_TO', 'FOLLOWED_BY'\n",
    "    ]\n",
    "    for rel in relationships:\n",
    "        result = session.run(f\"MATCH ()-[r:{rel}]->() RETURN count(r) as count\")\n",
    "        rel_counts[rel] = result.single()['count']\n",
    "\n",
    "print(\"Graph Statistics:\")\n",
    "print(\"\\nNode Counts:\")\n",
    "for label, count in node_counts.items():\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "print(\"\\nRelationship Counts:\")\n",
    "for rel, count in rel_counts.items():\n",
    "    print(f\"  {rel}: {count}\")\n",
    "\n",
    "print(f\"\\nTotal Nodes: {sum(node_counts.values())}\")\n",
    "print(f\"Total Relationships: {sum(rel_counts.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Product Discussion Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_query = \"\"\"\n",
    "Which products are most frequently discussed together in the same insights? \n",
    "Show pairs of products that appear in the same insights.\n",
    "\"\"\"\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\"), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": pattern_query})\n",
    "print(f\"\\nResult: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Evolution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_query = \"\"\"\n",
    "How does the discussion evolve over time? \n",
    "Show the progression of topics (insight categories) throughout the episode timeline.\n",
    "\"\"\"\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0), \n",
    "    graph=enhanced_graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": evolution_query})\n",
    "print(f\"\\nResult: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close Neo4j Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n",
    "print(\"Neo4j connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLLAMA LLM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
